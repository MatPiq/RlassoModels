{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "282d3646",
   "metadata": {},
   "source": [
    "# Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fce985",
   "metadata": {},
   "source": [
    "RlassoModels includes four estimators `Rlasso`, `RlassoLogit`, `RlassoPDS` and `RlassoIV`. The dataset from Acemoglu, Johnson and Robinson (2001) will be used as a running example, to highlight the different models. This is dataset is also used for various examples in the `stata` packages `lassopack` and `pdslasso` on which RlassoModels is mostly based, see help files: [lassopack](https://statalasso.github.io/docs/lassopack/help/rlasso_help/) and [pdslasso](https://statalasso.github.io/docs/pdslasso/ivlasso_help/) by Ahrens, Hansen & Schaffer, 2018, 2020) and also the R version [HDM](https://arxiv.org/abs/1603.01700) (Chernozkukov, Hansen & Spindler, 2016). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79f7ea0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from rlassomodels import Rlasso, RlassoPDS, RlassoIV\n",
    "from sklearn.linear_model import LassoCV, LassoLarsIC, LassoLarsCV\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.testing import assert_equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8115a8a9-751b-4bc4-a754-733c66588b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions: (64, 36)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shortnam</th>\n",
       "      <th>logpgp95</th>\n",
       "      <th>avexpr</th>\n",
       "      <th>lat_abst</th>\n",
       "      <th>logem4</th>\n",
       "      <th>edes1975</th>\n",
       "      <th>avelf</th>\n",
       "      <th>temp1</th>\n",
       "      <th>temp2</th>\n",
       "      <th>temp3</th>\n",
       "      <th>...</th>\n",
       "      <th>zinc</th>\n",
       "      <th>oilres</th>\n",
       "      <th>baseco</th>\n",
       "      <th>_merge</th>\n",
       "      <th>indtime</th>\n",
       "      <th>euro1900</th>\n",
       "      <th>democ1</th>\n",
       "      <th>cons1</th>\n",
       "      <th>democ00a</th>\n",
       "      <th>cons00a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AGO</td>\n",
       "      <td>7.770645</td>\n",
       "      <td>5.363636</td>\n",
       "      <td>0.136667</td>\n",
       "      <td>5.634789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.772755</td>\n",
       "      <td>26.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>146000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>matched (3)</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ARG</td>\n",
       "      <td>9.133459</td>\n",
       "      <td>6.386364</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>4.232656</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.176932</td>\n",
       "      <td>17.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46900.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>matched (3)</td>\n",
       "      <td>170.0</td>\n",
       "      <td>60.000004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AUS</td>\n",
       "      <td>9.897972</td>\n",
       "      <td>9.318182</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>2.145931</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.112797</td>\n",
       "      <td>17.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>99100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>matched (3)</td>\n",
       "      <td>94.0</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BFA</td>\n",
       "      <td>6.845880</td>\n",
       "      <td>4.454545</td>\n",
       "      <td>0.144444</td>\n",
       "      <td>5.634789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.546718</td>\n",
       "      <td>29.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>matched (3)</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BGD</td>\n",
       "      <td>6.877296</td>\n",
       "      <td>5.136364</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>4.268438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>matched (3)</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  shortnam  logpgp95    avexpr  lat_abst    logem4  edes1975     avelf  temp1  \\\n",
       "0      AGO  7.770645  5.363636  0.136667  5.634789       0.0  0.772755   26.0   \n",
       "1      ARG  9.133459  6.386364  0.377778  4.232656      90.0  0.176932   17.0   \n",
       "2      AUS  9.897972  9.318182  0.300000  2.145931      99.0  0.112797   17.0   \n",
       "3      BFA  6.845880  4.454545  0.144444  5.634789       0.0  0.546718   29.0   \n",
       "4      BGD  6.877296  5.136364  0.266667  4.268438       0.0  0.000000   25.0   \n",
       "\n",
       "   temp2  temp3  ...  zinc    oilres  baseco       _merge  indtime   euro1900  \\\n",
       "0   28.0   37.0  ...   0.0  146000.0     1.0  matched (3)     20.0   8.000000   \n",
       "1   25.0   40.0  ...   0.0   46900.0     1.0  matched (3)    170.0  60.000004   \n",
       "2   18.0   43.0  ...  12.0   99100.0     1.0  matched (3)     94.0  98.000000   \n",
       "3   38.0   48.0  ...   0.0       0.0     1.0  matched (3)     35.0   0.000000   \n",
       "4   29.0   42.0  ...   0.0       0.0     1.0  matched (3)     23.0   0.000000   \n",
       "\n",
       "   democ1  cons1  democ00a  cons00a  \n",
       "0     0.0    3.0       0.0      1.0  \n",
       "1     1.0    1.0       3.0      3.0  \n",
       "2    10.0    7.0      10.0      7.0  \n",
       "3     0.0    3.0       0.0      1.0  \n",
       "4     8.0    7.0       0.0      1.0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get data and select y and X\n",
    "ajr_df = pd.read_stata(\"https://statalasso.github.io/dta/AJR.dta\")\n",
    "X = ajr_df[[\"lat_abst\", \"edes1975\", \"avelf\", 'temp1', 'temp2', 'temp3', 'temp4', 'temp5', 'humid1',\n",
    "            \"humid2\", 'humid3', 'humid4' ,\"oilres\",\"steplow\", \"deslow\", \"stepmid\",\"desmid\", \"drystep\", \n",
    "            \"drywint\", \"landlock\", \"goldm\", \"iron\", \"silv\", \"zinc\"]]\n",
    "\n",
    "y = ajr_df[\"logpgp95\"]\n",
    "print(f\"Dimensions: {ajr_df.shape}\")\n",
    "ajr_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52559eae-5b4a-40be-8aca-02bcd09d40a4",
   "metadata": {},
   "source": [
    "### Rlasso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18cc145-3ef8-48b5-8026-c62f40602005",
   "metadata": {},
   "source": [
    "The class `Rlasso` is a [scikit-learn](https://scikit-learn.org/stable/) compatible estimator that implements the lasso and square-root lasso with data-driven and theoretically justified penalty level (see: Belloni et al.,2011, 2013). It adopts the syntax where all hyperparameters are definied upon class instantiation and data, or data-dependent arguments, is passed to the `fit()` method. This for example means that it can be passed to a [pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html). In adition, it is also possible to call `fit_formula()` which uses `R`-style model specification, made possible by the package [`patsy`](https://patsy.readthedocs.io/en/latest/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4b225b-ec65-41e0-9d94-64e0c104cea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model and fit\n",
    "rlasso = Rlasso(post=True, sqrt=False, cov_type=\"robust\")\n",
    "res1 = rlasso.fit(X,y)\n",
    "# fit same model but using formula\n",
    "formula = \"logpgp95 ~ \" + \" + \".join(X.columns)\n",
    "res2 = rlasso.fit_formula(formula, data=ajr_df)\n",
    "\n",
    "assert_equal(res1.coef_, res2.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2e467b-1c22-4533-b24f-ee2a62829592",
   "metadata": {},
   "source": [
    "We can compare the results of different `Rlasso` specifications to common alternatives for choosing $\\lambda$, featured in `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde0f227-9735-4928-8b52-fdb247491228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define models\n",
    "models = {\n",
    "          \"rlasso\": Rlasso(post=False),  # post-lasso is default\n",
    "          \"sqrt-rlasso\": Rlasso(sqrt=True, post=False),\n",
    "          \"rlasso-post\": Rlasso(),\n",
    "          \"AIC\": LassoLarsIC(criterion=\"aic\", normalize=False),\n",
    "          \"BIC\": LassoLarsIC(criterion=\"bic\", normalize=False),\n",
    "          \"CV\": LassoLarsCV(cv=5,normalize=False)\n",
    "          }\n",
    "          \n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    tmp_res = model.fit(X,y)\n",
    "    results[name] = np.array([tmp_res.intercept_] + tmp_res.coef_.tolist())\n",
    "    \n",
    "pd.DataFrame(results, index=[\"intercept\"] + X.columns.tolist()).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd549bf-23b6-41df-b4f5-a1be8557d263",
   "metadata": {},
   "source": [
    "As can be seen, rlasso tends to produce sparse solutions compared to cross-validation and in this example, selecting other variables than both AIC and BIC. To get an insight into the performance of Rlasso, estimates can be compared to the oracle estimator of running OLS only on active components. As can be seen from the example below, post-rlasso, that is running OLS on the rlasso selected components, significantly outperforms all other models and achives near oracle performance. Looking at the second plot, it is easy to see that this must be the case since rlasso almost always selects all the correct components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b6a6d2-b207-4d8c-80a3-e052d9c7927b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sparse_dgf():\n",
    "    \"\"\"\n",
    "    Data-generating function following Belloni (2011).\n",
    "    Taken from statsmodels tests:\n",
    "    https://github.com/statsmodels/statsmodels/blob/c1e30d9534dbe56346e50517da4dacf023a4aad7\n",
    "    /statsmodels/regression/tests/test_regression.py#L1311\n",
    "    \"\"\"\n",
    "    # Based on the example in the Belloni paper\n",
    "    n = 100\n",
    "    p = 500\n",
    "    ii = np.arange(p)\n",
    "    cx = 0.5 ** np.abs(np.subtract.outer(ii, ii))\n",
    "    cxr = np.linalg.cholesky(cx)\n",
    "\n",
    "    X = np.dot(np.random.normal(size=(n, p)), cxr.T)\n",
    "    b = np.zeros(p)\n",
    "    b[:5] = [1, 1, 1, 1, 1]\n",
    "    y = np.dot(X, b) + 0.5 * np.random.normal(size=n)\n",
    "\n",
    "    return X, y, b, cx\n",
    "\n",
    "\n",
    "\n",
    "oracle_ratio = defaultdict(list)\n",
    "correct_selected = defaultdict(list)\n",
    "\n",
    "n_sims = 500\n",
    "models = {\n",
    "          \"rlasso\":Rlasso(post=False),\n",
    "          \"post-rlasso\":Rlasso(),\n",
    "          \"AIC\": LassoLarsIC(normalize=False,noise_variance=0.5),# needs sigma when p>n\n",
    "          \"BIC\": LassoLarsIC(normalize=False,noise_variance=0.5),# needs sigma when p>n\n",
    "          \"CV\": LassoLarsCV(cv=5,normalize=False)\n",
    "          }\n",
    "\n",
    "def oracle_sim():\n",
    "    for _ in range(n_sims):\n",
    "        X,y,b,cx = sparse_dgf()\n",
    "        # oracle estimator (OLS) on true support\n",
    "        X_oracle = X[:,:5]\n",
    "        oracle_est = np.zeros(X.shape[1])\n",
    "        oracle_est[:5] = np.linalg.solve(X_oracle.T@X_oracle, X_oracle.T@y)\n",
    "\n",
    "        oracle_e = np.zeros(X.shape[1])\n",
    "        oracle_e = oracle_est - b\n",
    "\n",
    "        oracle_selected = oracle_est != 0\n",
    "        denom = np.sqrt(np.dot(oracle_e, np.dot(cx, oracle_e)))\n",
    "\n",
    "        for name, model in models.items():\n",
    "\n",
    "\n",
    "            # get estimate\n",
    "            est = model.fit(X, y)\n",
    "            e = est.coef_ - b\n",
    "            selected = est.coef_ != 0\n",
    "            numer = np.sqrt(np.dot(e, np.dot(cx, e)))\n",
    "\n",
    "            # get ratio\n",
    "            oracle_ratio[name].append(numer / denom)\n",
    "            # correctly selected components\n",
    "            correct_selected[name].append((oracle_selected == selected).sum())\n",
    "\n",
    "    # plot results from simulations\n",
    "    # oracle ratio\n",
    "    fig, axs = plt.subplots(ncols=2, dpi=100, figsize=(10,4))\n",
    "    axs[0].boxplot([oracle_ratio[\"post-rlasso\"], oracle_ratio[\"rlasso\"], \n",
    "                    oracle_ratio[\"AIC\"], oracle_ratio[\"BIC\"],\n",
    "                    oracle_ratio[\"CV\"]])\n",
    "\n",
    "    axs[0].set_ylabel(\"Empirical risk\")\n",
    "    axs[0].set_xlabel(\"Model\")\n",
    "    axs[0].set_xticks([1,2,3,4,5],[\"post-rlasso\", \"rlasso\", \"AIC\", \"BIC\", \"CV\"])\n",
    "\n",
    "    # correctly selected components\n",
    "    axs[1].boxplot([correct_selected[\"post-rlasso\"], correct_selected[\"rlasso\"], \n",
    "                    correct_selected[\"AIC\"], correct_selected[\"BIC\"], \n",
    "                    correct_selected[\"CV\"]])\n",
    "    axs[1].set_ylabel(\"Correctly selected components\")\n",
    "    axs[1].set_xlabel(\"Mode\")\n",
    "    axs[1].set_xticks([1,2,3,4,5],[\"post-rlasso\", \"rlasso\", \"AIC\", \"BIC\", \"CV\"])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "oracle_sim()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd98507b-f45b-4fc3-be6c-3d6e5e9b6ebf",
   "metadata": {
    "tags": []
   },
   "source": [
    "### RlassoPDS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995a11b2-8f76-4d69-926c-227ca56aa2c4",
   "metadata": {},
   "source": [
    "`RlassoPDS` extends `Rlasso` to be used for causal inference in the following setting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c15aa0-f5cf-41f3-ae3c-a06bf0f34b6b",
   "metadata": {},
   "source": [
    "$$\n",
    "y_{i}=\\alpha d_{i}+x_{i}^{\\prime} \\beta+\\varepsilon_{i}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6ddee0-f717-4090-b9db-9e8c05112f0e",
   "metadata": {},
   "source": [
    "Where $d_{i}$ is a scalar exogenous variable (can also be low-dimensional vector) for which we are interested in a obtaining a consistent estimate with valid standard errors and test statistics in the presence of high-dimensional $x_i$. This is possible using the *post-double-selection* (PDS) and *post-regularization* (CHS) methodology developed in a series of papers by Belloni et al. (2011, 2013, 2014) and Chernozhukov et al. (2015). By default both methods are used. Since the purpose is inference and we're interested in a limited amount of variables, the class is purposly no longer directly scikit-learn compatible. Instead, it uses the econometrics package [linearmodels](https://bashtage.github.io/linearmodels/) in the final estimation stage to produce relevant outputs. This is shown below by considering a case where we want to perform inference for the variable `avexpr`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fab146fd-9ef3-43d5-a1be-3fc5b5ac952e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Model Comparison              \n",
      "============================================\n",
      "                            PDS          CHS\n",
      "--------------------------------------------\n",
      "Dep. Variable          logpgp95     logpgp95\n",
      "Estimator                   OLS          OLS\n",
      "No. Observations             64           64\n",
      "Cov. Est.            unadjusted   unadjusted\n",
      "R-squared                0.7261       0.4199\n",
      "Adj. R-squared           0.7075       0.4107\n",
      "F-statistic              169.67       46.318\n",
      "P-value (F-stat)         0.0000    1.005e-11\n",
      "================== ============ ============\n",
      "const                 5.7641***             \n",
      "                       (0.3774)             \n",
      "avexpr                0.3913***    0.3913***\n",
      "                       (0.0562)     (0.0575)\n",
      "avelf                -0.9975***             \n",
      "                       (0.2474)             \n",
      "edes1975              0.0091***             \n",
      "                       (0.0032)             \n",
      "zinc                    -0.0079             \n",
      "                       (0.0281)             \n",
      "--------------------------------------------\n",
      "\n",
      "Std. Errors reported in parentheses\n",
      "Std. Errors and Test statistics valid for\n",
      "['avexpr']\n"
     ]
    }
   ],
   "source": [
    "d_exog = ajr_df[\"avexpr\"]\n",
    "rlasso_pds = RlassoPDS().fit(X,y,D_exog=d_exog)\n",
    "\n",
    "print(rlasso_pds.summary())\n",
    "print(f\"Std. Errors and Test statistics valid for\\n{rlasso_pds.valid_vars_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3405c83-a331-461c-9e02-40cbdf85f95f",
   "metadata": {},
   "source": [
    "### RlassoIV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211d40ef-e3bc-4197-8cc5-0ba63c0c77e1",
   "metadata": {},
   "source": [
    "`RlassoIV` is used when one wants to use instruments in order to estimate low-dimensional endogenous variables in the setting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978b512e-c6e0-40c7-8f09-9b9c1281f362",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "&y_{i}=\\alpha d_{i}+x_{i}^{\\prime} \\beta+\\varepsilon_{i} \\\\\n",
    "&d_{i}=x_{i}^{\\prime} \\gamma+z_{i}^{\\prime} \\delta+u_{i}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c146d984-f4b8-4f4a-9fb2-400a50af5ac3",
   "metadata": {},
   "source": [
    "where both `z_i` and `x_i` are possibily high-dimensional. Note that we can still include exogonous variables. In the example below, we now treat `avexpr` as endogenous and specify that rigorous lasso should be used both to select instruments and controls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c08cdcd6-1625-4c13-9584-f96401d7a16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data and select y and X\n",
    "ajr_df = pd.read_stata(\"https://statalasso.github.io/dta/AJR.dta\")\n",
    "\n",
    "# some instruments have NaN values\n",
    "ajr_df.dropna(inplace=True)\n",
    "\n",
    "X = ajr_df[[\"edes1975\", 'temp1', 'temp2', 'temp3', 'temp4', 'temp5', 'humid1',\n",
    "            \"humid2\", 'humid3', 'humid4' ,\"oilres\",\"steplow\", \"deslow\", \"stepmid\",\"desmid\", \"drystep\", \n",
    "            \"drywint\", \"landlock\", \"goldm\", \"iron\", \"silv\", \"zinc\", \"lat_abst\", \"avelf\"]]\n",
    "\n",
    "y = ajr_df[\"logpgp95\"]\n",
    "# subset instruments and endogenous var\n",
    "Z = ajr_df[[\"logem4\", \"euro1900\", \"democ1\", \"cons1\",\"democ00a\", \"cons00a\"]]\n",
    "d_endog = ajr_df[\"avexpr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0ec2cc0-b694-4d20-bac1-ee954f616216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model Comparison                 \n",
      "==================================================\n",
      "                                PDS            CHS\n",
      "--------------------------------------------------\n",
      "Dep. Variable              logpgp95       logpgp95\n",
      "Estimator                   IV-2SLS        IV-2SLS\n",
      "No. Observations                 59             59\n",
      "Cov. Est.                unadjusted     unadjusted\n",
      "R-squared                    0.4334        -0.5831\n",
      "Adj. R-squared               0.3915        -0.6104\n",
      "F-statistic                  66.517         7.3846\n",
      "P-value (F-stat)          1.232e-13         0.0066\n",
      "==================     ============   ============\n",
      "const                       3.1400*               \n",
      "                           (1.6429)               \n",
      "avelf                     -0.7468**               \n",
      "                           (0.3605)               \n",
      "edes1975                     0.0025               \n",
      "                           (0.0070)               \n",
      "zinc                        -0.0658               \n",
      "                           (0.0523)               \n",
      "avexpr                    0.8034***      0.9095***\n",
      "                           (0.2687)       (0.3347)\n",
      "==================== ============== ==============\n",
      "Instruments                euro1900    instruments\n",
      "                             logem4               \n",
      "--------------------------------------------------\n",
      "\n",
      "Std. Errors reported in parentheses\n",
      "Std. errors and Test statistics valid for\n",
      "['avexpr']\n"
     ]
    }
   ],
   "source": [
    "rlasso_iv = RlassoIV(select_X=True, select_Z=True)\n",
    "\n",
    "rlasso_iv.fit(X, y, D_exog=None, D_endog=d_endog, Z=Z)\n",
    "\n",
    "print(rlasso_iv.summary())\n",
    "print(f\"Std. errors and Test statistics valid for\\n{rlasso_iv.valid_vars_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2aa2634-cc87-46e5-bdc6-2242f06145ef",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23c99c2-d90c-4f6e-a233-9df92aae6eee",
   "metadata": {},
   "source": [
    "Acemoglu, D., Johnson, S., & Robinson, J. A. (2001). The colonial origins of comparative development: An empirical investigation. American economic review, 91(5), 1369-1401.\n",
    "\n",
    "Ahrens, A., Hansen, C. B., & Schaffer, M. (2020). LASSOPACK: Stata module for lasso, square-root lasso, elastic net, ridge, adaptive lasso estimation and cross-validation.\n",
    "\n",
    "Ahrens, A., Hansen, C.B., Schaffer, M.E. 2018. pdslasso and ivlasso: Programs for post-selection and post-regularization OLS or IV estimation and inference. http://ideas.repec.org/c/boc/bocode/s458459.html\n",
    "\n",
    "Chernozhukov, V., Hansen, C., & Spindler, M. (2016). hdm: High-dimensional metrics. arXiv preprint arXiv:1608.00354.\n",
    "\n",
    "A. Belloni, D. Chen, V. Chernozhukov and C. Hansen (2012). Sparse models and methods for optimal instruments with an application to eminent domain. Econometrica 80 (6), 2369-2429.\n",
    "\n",
    "A. Belloni, V. Chernozhukov and C. Hansen (2013). Inference for high-dimensional sparse econometric models. In Advances in Economics and Econometrics: 10th World Congress, Vol. 3: Econometrics, Cambridge University Press: Cambridge, 245-295.\n",
    "\n",
    "A. Belloni, V. Chernozhukov, C. Hansen (2014). Inference on treatment effects after selection among high-dimensional controls. The Review of Economic Studies 81(2), 608-650.."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
