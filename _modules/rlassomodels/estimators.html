
<!DOCTYPE html>

<html lang="Python">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>rlassomodels.estimators &#8212; RlassoModels  documentation</title>
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/alabaster.css" />
    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/js/copybutton.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
   
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <h1>Source code for rlassomodels.estimators</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">warnings</span>

<span class="kn">import</span> <span class="nn">cvxpy</span> <span class="k">as</span> <span class="nn">cp</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">numpy.linalg</span> <span class="k">as</span> <span class="nn">la</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">scipy.stats</span> <span class="k">as</span> <span class="nn">st</span>
<span class="kn">from</span> <span class="nn">_solver_fast</span> <span class="kn">import</span> <span class="n">_cd_solver</span>
<span class="kn">from</span> <span class="nn">linearmodels.iv</span> <span class="kn">import</span> <span class="n">IV2SLS</span><span class="p">,</span> <span class="n">compare</span>
<span class="kn">from</span> <span class="nn">patsy</span> <span class="kn">import</span> <span class="n">dmatrices</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">ClassifierMixin</span><span class="p">,</span> <span class="n">RegressorMixin</span>
<span class="kn">from</span> <span class="nn">sklearn.utils.validation</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">check_array</span><span class="p">,</span>
    <span class="n">check_is_fitted</span><span class="p">,</span>
    <span class="n">check_random_state</span><span class="p">,</span>
    <span class="n">check_X_y</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">statsmodels.api</span> <span class="kn">import</span> <span class="n">add_constant</span>


<div class="viewcode-block" id="Rlasso"><a class="viewcode-back" href="../../generated/rlassomodels.Rlasso.html#rlassomodels.Rlasso">[docs]</a><span class="k">class</span> <span class="nc">Rlasso</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">RegressorMixin</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Rigorous Lasso and Sqrt-Lasso estimator with</span>
<span class="sd">    theoretically motivated and data-driven penalty level.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    post: bool, default=True</span>
<span class="sd">        If True, post-lasso is used to estimate betas,</span>
<span class="sd">        meaning that features selected by rlasso are</span>
<span class="sd">        estimated by OLS in the final model, as outlined</span>
<span class="sd">        in [2]_.</span>

<span class="sd">    sqrt: bool, default=False</span>
<span class="sd">        If True, square-root lasso criterion is minimized</span>
<span class="sd">        is minimized instead of normal lasso. See [1]_ and</span>
<span class="sd">        notes below for details.</span>

<span class="sd">    fit_intercept: bool, default=True</span>
<span class="sd">        If True, an unpenalized intercept is estimated</span>
<span class="sd">        by mean centering the data prior to estimation.</span>

<span class="sd">    cov_type: str, default=&quot;nonrobust&quot;</span>
<span class="sd">        Type of covariance matrix. Right now the</span>
<span class="sd">        supported types are: &quot;nonrobust&quot;, &quot;robust&quot;.</span>

<span class="sd">    x_dependent: bool, default=False</span>
<span class="sd">        If True, the alternative and less conservative lambda</span>
<span class="sd">        is estimated by simulation using the conditional</span>
<span class="sd">        distribution of the design matrix.</span>

<span class="sd">    n_sim: int, default=5000</span>
<span class="sd">        Number of simulations to be performed for x-dependent</span>
<span class="sd">        lambda calculation.</span>

<span class="sd">    random_state: int, default=None</span>
<span class="sd">        Random seed used for simulations if `x_dependent` is</span>
<span class="sd">        set to `True`.</span>

<span class="sd">    lasso_psi: bool, default=False</span>
<span class="sd">        By default post-lasso is the default method for obtaining</span>
<span class="sd">        residuals in the</span>

<span class="sd">    prestd: bool, default=False</span>
<span class="sd">        If True, the data is prestandardized instead of</span>
<span class="sd">        on the fly by penalty loadings. Currently only</span>
<span class="sd">        supports homoscedastic case.</span>

<span class="sd">    n_corr: int, default=5</span>
<span class="sd">        Number of most correlated variables to be used in the</span>
<span class="sd">        for initial calculation of the residuals.</span>

<span class="sd">    c: float, default=1.1</span>
<span class="sd">        Slack parameter used in the lambda calculation. From</span>
<span class="sd">        [3]_ &quot;c needs to be greater than 1 for the regularization</span>
<span class="sd">        event to hold asymptotically, but not too high as the</span>
<span class="sd">        shrinkage bias is increasing in c.&quot;</span>

<span class="sd">    gamma: float, optional=None</span>
<span class="sd">        Regularization parameter, where the probability of</span>
<span class="sd">        selecting the correct model is given by 1-gamma.</span>
<span class="sd">        If not specified, the the value is set to:</span>
<span class="sd">        0.1 / np.log(n)</span>

<span class="sd">    max_iter: int, default=2</span>
<span class="sd">        Maximum number of iterations to perform in the iterative</span>
<span class="sd">        estimation procedure to obtain the Rlasso estimates.</span>

<span class="sd">    conv_tol: float, default=1e-4</span>
<span class="sd">        Tolerance for the convergence of the iterative estimation</span>
<span class="sd">        procedure.</span>

<span class="sd">    solver: str, default=&quot;cd&quot;</span>
<span class="sd">        Solver to be used for the iterative estimation procedure.</span>
<span class="sd">        Alternatives are:</span>
<span class="sd">        &quot;cd&quot; - coordinate descent method.</span>
<span class="sd">        &quot;cvxpy&quot; - cvxpy solver.</span>

<span class="sd">    cd_max_iter: int, default=10000</span>
<span class="sd">        Maximum number of iterations to be perform by the coordinate</span>
<span class="sd">        descent algorithm before stopping.</span>

<span class="sd">    cd_tol: float, default=1e-10</span>
<span class="sd">        Convergence tolerance for the coordinate descent algorithm.</span>

<span class="sd">    cvxpy_opts: dict, default=None</span>
<span class="sd">        Additional options to be passed to the cvxpy solver. See cvxpy</span>
<span class="sd">        documentation for more details:</span>
<span class="sd">        https://www.cvxpy.org/tutorial/advanced/index.html#solve-method-options</span>

<span class="sd">    zero_tol: float, default=1e-4</span>
<span class="sd">        Tolerance for the rounding of estimated coefficients to zero.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    coef_: numpy.array, shape (n_features,)</span>
<span class="sd">        Estimated coefficients.</span>

<span class="sd">    intercept_: float</span>
<span class="sd">        Estimated intercept.</span>

<span class="sd">    lambd_: float</span>
<span class="sd">        Estimated lambda/overall penalty level.</span>

<span class="sd">    psi_: numpy.array, shape (n_features, n_features)</span>
<span class="sd">        Estimated penalty loadings.</span>

<span class="sd">    n_iter_: int</span>
<span class="sd">        Number of iterations performed by the rlasso algorithm.</span>

<span class="sd">    n_features_in_: int</span>
<span class="sd">        Number of features in the input data.</span>

<span class="sd">    n_samples_: int</span>
<span class="sd">        Number of samples/observations in the input data.</span>

<span class="sd">    feature_names_in_: str</span>
<span class="sd">        Feature names of ``X``. Only stored if</span>
<span class="sd">        the input data is of type  ``pd.DataFrame``.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    Rlasso minimizes the following loss function:</span>


<span class="sd">    .. math:: \widehat{\\beta} = \\arg \min \\frac{1}{n} \lVert y_i - x_i&#39;\\beta \\rVert_2^2 +\\frac{\lambda}{n} \sum^p_{j=1}\psi_j|\\beta_j|</span>

<span class="sd">    Or in the case of square-root lasso when ``sqrt=True``:</span>

<span class="sd">    .. math:: \widehat{\\beta} = \\arg \min \\frac{1}{\sqrt{n}} \lVert y_i - x_i&#39;\\beta \\rVert_2 + \\frac{\lambda}{n} \sum^p_{j=1}\psi_j|\\beta_j|</span>


<span class="sd">    Where :math:`\psi_{j}` are regressor specific penalty loadings and</span>
<span class="sd">    :math:`\lambda` is the overall penalty level. For an introduction to</span>
<span class="sd">    the rigorous lasso algorithm to estimate the penalty loadings and</span>
<span class="sd">    the overall penalty level see [3]_ and [4]_.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>

<span class="sd">    .. [1] Belloni, A., Chernozhukov, V., &amp; Wang, L. (2011).</span>
<span class="sd">       Square-root lasso: pivotal recovery of sparse signals via conic programming.</span>
<span class="sd">       Biometrika, 98(4), 791-806.</span>

<span class="sd">    .. [2] Belloni, A., &amp; Chernozhukov, V. (2013). Least squares after model selection</span>
<span class="sd">       in high-dimensional sparse models. Bernoulli, 19(2), 521-547.</span>

<span class="sd">    .. [3] Ahrens, A., Hansen, C. B., &amp; Schaffer, M. E. (2020). lassopack: Model</span>
<span class="sd">       selection and prediction with regularized regression in Stata.</span>
<span class="sd">       The Stata Journal, 20(1), 176-235.</span>

<span class="sd">    .. [4] Chernozhukov, V., Hansen, C., &amp; Spindler, M. (2016).</span>
<span class="sd">       hdm: High-dimensional metrics. arXiv preprint arXiv:1608.00354.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from rlasso import Rlasso</span>
<span class="sd">    &gt;&gt;&gt; X = np.random.randn(100, 5)</span>
<span class="sd">    &gt;&gt;&gt; y = np.random.randn(100)</span>
<span class="sd">    &gt;&gt;&gt; rlasso = Rlasso()</span>
<span class="sd">    &gt;&gt;&gt; rlasso.fit(X, y)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">post</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">sqrt</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">fit_intercept</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">cov_type</span><span class="o">=</span><span class="s2">&quot;nonrobust&quot;</span><span class="p">,</span>
        <span class="n">x_dependent</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">lasso_psi</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">prestd</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">n_corr</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
        <span class="n">max_iter</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="n">conv_tol</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span>
        <span class="n">n_sim</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span>
        <span class="n">c</span><span class="o">=</span><span class="mf">1.1</span><span class="p">,</span>
        <span class="n">gamma</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">solver</span><span class="o">=</span><span class="s2">&quot;cd&quot;</span><span class="p">,</span>
        <span class="n">cd_max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
        <span class="n">cd_tol</span><span class="o">=</span><span class="mf">1e-10</span><span class="p">,</span>
        <span class="n">cvxpy_opts</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">zero_tol</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span>
    <span class="p">):</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">post</span> <span class="o">=</span> <span class="n">post</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sqrt</span> <span class="o">=</span> <span class="n">sqrt</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fit_intercept</span> <span class="o">=</span> <span class="n">fit_intercept</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cov_type</span> <span class="o">=</span> <span class="n">cov_type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">x_dependent</span> <span class="o">=</span> <span class="n">x_dependent</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lasso_psi</span> <span class="o">=</span> <span class="n">lasso_psi</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prestd</span> <span class="o">=</span> <span class="n">prestd</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_corr</span> <span class="o">=</span> <span class="n">n_corr</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span> <span class="o">=</span> <span class="n">max_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv_tol</span> <span class="o">=</span> <span class="n">conv_tol</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_sim</span> <span class="o">=</span> <span class="n">n_sim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">c</span> <span class="o">=</span> <span class="n">c</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">gamma</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">solver</span> <span class="o">=</span> <span class="n">solver</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cd_max_iter</span> <span class="o">=</span> <span class="n">cd_max_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cd_tol</span> <span class="o">=</span> <span class="n">cd_tol</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">zero_tol</span> <span class="o">=</span> <span class="n">zero_tol</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cvxpy_opts</span> <span class="o">=</span> <span class="n">cvxpy_opts</span>

    <span class="k">def</span> <span class="nf">_psi_calc</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">v</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;Calculate the penalty loadings.&quot;&quot;&quot;</span>

        <span class="c1"># TODO Implement cluster robust covariance</span>
        <span class="c1"># if prestandardized X, set loadings to ones</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">prestd</span><span class="p">:</span>
            <span class="n">psi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_features_in_</span><span class="p">)</span>

        <span class="c1"># sqrt case</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">sqrt</span><span class="p">:</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cov_type</span> <span class="o">==</span> <span class="s2">&quot;nonrobust&quot;</span><span class="p">:</span>
                <span class="n">psi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">X</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>

            <span class="c1"># heteroscedastic robust case</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">cov_type</span> <span class="o">==</span> <span class="s2">&quot;robust&quot;</span> <span class="ow">and</span> <span class="n">v</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">Xv2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">&quot;ij, i -&gt; j&quot;</span><span class="p">,</span> <span class="n">X</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">v</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
                <span class="n">psi_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">X</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
                <span class="n">psi_2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">Xv2</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">v</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>
                <span class="n">psi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">psi_1</span><span class="p">,</span> <span class="n">psi_2</span><span class="p">)</span>
            <span class="c1"># clustered</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Cluster robust loadings not implemented&quot;</span><span class="p">)</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">cov_type</span> <span class="o">==</span> <span class="s2">&quot;nonrobust&quot;</span><span class="p">:</span>
            <span class="n">psi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">X</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">cov_type</span> <span class="o">==</span> <span class="s2">&quot;robust&quot;</span> <span class="ow">and</span> <span class="n">v</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">Xe2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">&quot;ij, i -&gt; j&quot;</span><span class="p">,</span> <span class="n">X</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">v</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
            <span class="n">psi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">Xe2</span> <span class="o">/</span> <span class="n">n</span><span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Cluster robust loadings not implemented&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">nopen_idx_</span><span class="p">:</span>
            <span class="n">psi</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">nopen_idx_</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>

        <span class="k">return</span> <span class="n">psi</span>

    <span class="k">def</span> <span class="nf">_lambd_calc</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">n</span><span class="p">,</span>
        <span class="n">p</span><span class="p">,</span>
        <span class="n">X</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">v</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">s1</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">psi</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>  <span class="c1"># sourcery skip: remove-redundant-if</span>
        <span class="sd">&quot;&quot;&quot;Calculate the lambda/overall penalty level.&quot;&quot;&quot;</span>

        <span class="c1"># TODO Always return both lambda and lambda scaled by RMSE</span>
        <span class="c1"># for the purpose of comparison between specifications.</span>

        <span class="c1"># TODO: Implement cluster robust case</span>

        <span class="c1"># empirical gamma if not provided</span>
        <span class="n">gamma</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="ow">or</span> <span class="mf">0.1</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">psi</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">psi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">psi</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">sqrt</span><span class="p">:</span>
            <span class="n">lf</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">c</span>
            <span class="c1"># x-independent (same for robust and nonrobust)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">x_dependent</span><span class="p">:</span>
                <span class="n">prob</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="n">gamma</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">p</span><span class="p">)))</span>
                <span class="n">lambd</span> <span class="o">=</span> <span class="n">lf</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="o">*</span> <span class="n">prob</span>

            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">cov_type</span> <span class="o">==</span> <span class="s2">&quot;nonrobust&quot;</span><span class="p">:</span>
                <span class="n">Xpsi</span> <span class="o">=</span> <span class="n">X</span> <span class="o">@</span> <span class="n">la</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">psi</span><span class="p">)</span>
                <span class="n">sims</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_sim</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_sim</span><span class="p">):</span>
                    <span class="n">g</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">random_state_</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
                    <span class="n">sg</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">g</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
                    <span class="n">sims</span><span class="p">[</span><span class="n">r</span><span class="p">]</span> <span class="o">=</span> <span class="n">sg</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">Xpsi</span> <span class="o">*</span> <span class="n">g</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)))</span>

                <span class="n">lambd</span> <span class="o">=</span> <span class="n">lf</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">sims</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">gamma</span><span class="p">)</span>

            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">cov_type</span> <span class="o">==</span> <span class="s2">&quot;robust&quot;</span><span class="p">:</span>
                <span class="n">Xpsi</span> <span class="o">=</span> <span class="n">X</span> <span class="o">@</span> <span class="n">la</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">psi</span><span class="p">)</span>
                <span class="n">sims</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_sim</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_sim</span><span class="p">):</span>
                    <span class="n">g</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">random_state_</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
                    <span class="n">sg</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">g</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
                    <span class="n">sims</span><span class="p">[</span><span class="n">r</span><span class="p">]</span> <span class="o">=</span> <span class="n">sg</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">Xpsi</span> <span class="o">*</span> <span class="n">v</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">g</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)))</span>

                <span class="n">lambd</span> <span class="o">=</span> <span class="n">lf</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">sims</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">gamma</span><span class="p">)</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Cluster robust penalty not implemented&quot;</span><span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>

            <span class="n">lf</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">c</span>
            <span class="c1"># homoscedasticity and x-independent case</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cov_type</span> <span class="o">==</span> <span class="s2">&quot;nonrobust&quot;</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">x_dependent</span><span class="p">:</span>
                <span class="k">assert</span> <span class="n">s1</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                <span class="n">proba</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="n">gamma</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">p</span><span class="p">)))</span>
                <span class="c1"># homoscedastic/non-robust case</span>
                <span class="n">lambd</span> <span class="o">=</span> <span class="n">lf</span> <span class="o">*</span> <span class="n">s1</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="o">*</span> <span class="n">proba</span>

            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">cov_type</span> <span class="o">==</span> <span class="s2">&quot;nonrobust&quot;</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">x_dependent</span><span class="p">:</span>
                <span class="k">assert</span> <span class="n">psi</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                <span class="n">sims</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_sim</span><span class="p">)</span>
                <span class="n">Xpsi</span> <span class="o">=</span> <span class="n">X</span> <span class="o">@</span> <span class="n">la</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">psi</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_sim</span><span class="p">):</span>
                    <span class="n">g</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">random_state_</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
                    <span class="n">sims</span><span class="p">[</span><span class="n">r</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">Xpsi</span> <span class="o">*</span> <span class="n">g</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)))</span>

                <span class="n">lambd</span> <span class="o">=</span> <span class="n">lf</span> <span class="o">*</span> <span class="n">s1</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">sims</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">gamma</span><span class="p">)</span>

            <span class="c1"># heteroscedastic/cluster robust and x-independent case</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">cov_type</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;robust&quot;</span><span class="p">,</span> <span class="s2">&quot;cluster&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">x_dependent</span><span class="p">:</span>

                <span class="n">proba</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="n">gamma</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">p</span><span class="p">)))</span>
                <span class="n">lambd</span> <span class="o">=</span> <span class="n">lf</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="o">*</span> <span class="n">proba</span>

            <span class="c1"># heteroscedastic/cluster robust and x-dependent case</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">cov_type</span> <span class="o">==</span> <span class="s2">&quot;robust&quot;</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">x_dependent</span><span class="p">:</span>
                <span class="n">sims</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_sim</span><span class="p">)</span>
                <span class="n">Xpsi</span> <span class="o">=</span> <span class="n">X</span> <span class="o">@</span> <span class="n">la</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">psi</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_sim</span><span class="p">):</span>
                    <span class="n">g</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">random_state_</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
                    <span class="n">sims</span><span class="p">[</span><span class="n">r</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">Xpsi</span> <span class="o">*</span> <span class="n">v</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">g</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)))</span>

                <span class="n">lambd</span> <span class="o">=</span> <span class="n">lf</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">sims</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">gamma</span><span class="p">)</span>

            <span class="c1"># heteroscedastic/cluster robust and x-dependent case</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Cluster robust penalty not implemented&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">lambd</span>

    <span class="k">def</span> <span class="nf">_cvxpy_solver</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">X</span><span class="p">,</span>
        <span class="n">y</span><span class="p">,</span>
        <span class="n">lambd</span><span class="p">,</span>
        <span class="n">psi</span><span class="p">,</span>
        <span class="n">n</span><span class="p">,</span>
        <span class="n">p</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Solve the lasso problem using cvxpy</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">beta</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">sqrt</span><span class="p">:</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">norm2</span><span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">X</span> <span class="o">@</span> <span class="n">beta</span><span class="p">)</span> <span class="o">/</span> <span class="n">cp</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">sum_squares</span><span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">X</span> <span class="o">@</span> <span class="n">beta</span><span class="p">)</span> <span class="o">/</span> <span class="n">n</span>

        <span class="n">reg</span> <span class="o">=</span> <span class="p">(</span><span class="n">lambd</span> <span class="o">/</span> <span class="n">n</span><span class="p">)</span> <span class="o">*</span> <span class="n">cp</span><span class="o">.</span><span class="n">norm1</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">psi</span><span class="p">)</span> <span class="o">@</span> <span class="n">beta</span><span class="p">)</span>
        <span class="n">objective</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">Minimize</span><span class="p">(</span><span class="n">loss</span> <span class="o">+</span> <span class="n">reg</span><span class="p">)</span>
        <span class="n">prob</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">Problem</span><span class="p">(</span><span class="n">objective</span><span class="p">)</span>
        <span class="n">prob</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">cvxpy_opts</span> <span class="ow">or</span> <span class="p">{})</span>

        <span class="c1"># round beta to zero if below threshold</span>
        <span class="n">beta</span> <span class="o">=</span> <span class="n">beta</span><span class="o">.</span><span class="n">value</span>
        <span class="n">beta</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">beta</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">zero_tol</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>

        <span class="k">return</span> <span class="n">beta</span>

    <span class="k">def</span> <span class="nf">_OLS</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Solve the OLS problem</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># add dim if X is 1-d</span>
        <span class="k">if</span> <span class="n">X</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">la</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">X</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">except</span> <span class="n">la</span><span class="o">.</span><span class="n">LinAlgError</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;Singular matrix encountered. invoking lstsq solver for OLS&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">la</span><span class="o">.</span><span class="n">lstsq</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">rcond</span><span class="o">=</span><span class="kc">None</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">_post_lasso</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Replace the non-zero lasso coefficients by OLS.&quot;&quot;&quot;</span>

        <span class="n">nonzero_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">beta</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">X_sub</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="n">nonzero_idx</span><span class="p">]</span>
        <span class="n">post_beta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_OLS</span><span class="p">(</span><span class="n">X_sub</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">beta</span><span class="p">[</span><span class="n">nonzero_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">post_beta</span>

        <span class="k">return</span> <span class="n">beta</span>

    <span class="k">def</span> <span class="nf">_starting_values</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">XX</span><span class="p">,</span> <span class="n">Xy</span><span class="p">,</span> <span class="n">lambd</span><span class="p">,</span> <span class="n">psi</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Calculate starting values for the lasso.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">sqrt</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">la</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">XX</span> <span class="o">+</span> <span class="n">lambd</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">psi</span><span class="o">**</span><span class="mi">2</span><span class="p">),</span> <span class="n">Xy</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">la</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">XX</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">+</span> <span class="n">lambd</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">psi</span><span class="o">**</span><span class="mi">2</span><span class="p">),</span> <span class="n">Xy</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">nopen_idx</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Helper function to fit the model.&quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;`max_iter` cannot be negative&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cov_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;nonrobust&quot;</span><span class="p">,</span> <span class="s2">&quot;robust&quot;</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;cov_type must be one of &#39;nonrobust&#39;, &#39;robust&#39;&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">solver</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;cd&quot;</span><span class="p">,</span> <span class="s2">&quot;cvxpy&quot;</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;solver must be one of &#39;cd&#39;, &#39;cvxpy&#39;&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">c</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;c should be greater than 1 for the regularization&quot;</span>
                <span class="s2">&quot; event to hold asymptotically&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">prestd</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">cov_type</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;robust&quot;</span><span class="p">,</span> <span class="s2">&quot;cluster&quot;</span><span class="p">):</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;prestd is not implemented for robust penalty. &quot;</span>
                <span class="s2">&quot;Data is assumed to be homoscedastic.&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">nopen_idx</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">nopen_idx</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;nopen_idx must be a list or numpy array&quot;</span><span class="p">)</span>

        <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">check_X_y</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">accept_sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">ensure_min_samples</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">nopen_idx_</span> <span class="o">=</span> <span class="n">nopen_idx</span>

        <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_features_in_</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">n</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># check random state</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_state_</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span>

        <span class="c1"># intercept and pre-standardization handling</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit_intercept</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">prestd</span><span class="p">:</span>
            <span class="n">X_mean</span><span class="p">,</span> <span class="n">y_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">X</span> <span class="o">-</span> <span class="n">X_mean</span><span class="p">,</span> <span class="n">y</span> <span class="o">-</span> <span class="n">y_mean</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">prestd</span><span class="p">:</span>
            <span class="n">X_std</span><span class="p">,</span> <span class="n">y_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">X</span> <span class="o">/</span> <span class="n">X_std</span><span class="p">,</span> <span class="n">y</span> <span class="o">/</span> <span class="n">y_std</span>

        <span class="c1"># pre-allocate arrays for coordinate descent solver</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">solver</span> <span class="o">==</span> <span class="s2">&quot;cd&quot;</span><span class="p">:</span>
            <span class="c1"># precompute XX and Xy crossprods</span>
            <span class="n">XX</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">X</span>
            <span class="n">Xy</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">y</span>

            <span class="c1"># make matrices fortran contiguous</span>
            <span class="n">XX</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asfortranarray</span><span class="p">(</span><span class="n">XX</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asfortranarray</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
            <span class="n">Xy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asfortranarray</span><span class="p">(</span><span class="n">Xy</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asfortranarray</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

        <span class="c1"># sqrt used under homoscedastic is one-step estimator</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">sqrt</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">cov_type</span> <span class="o">==</span> <span class="s2">&quot;nonrobust&quot;</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">x_dependent</span><span class="p">:</span>

            <span class="n">psi</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_psi_calc</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
            <span class="n">lambd</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lambd_calc</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">)</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">solver</span> <span class="o">==</span> <span class="s2">&quot;cd&quot;</span><span class="p">:</span>
                <span class="n">beta_ridge</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_starting_values</span><span class="p">(</span><span class="n">XX</span><span class="p">,</span> <span class="n">Xy</span><span class="p">,</span> <span class="n">lambd</span><span class="p">,</span> <span class="n">psi</span><span class="p">)</span>
                <span class="n">beta</span> <span class="o">=</span> <span class="n">_cd_solver</span><span class="p">(</span>
                    <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span>
                    <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
                    <span class="n">XX</span><span class="o">=</span><span class="n">XX</span><span class="p">,</span>
                    <span class="n">Xy</span><span class="o">=</span><span class="n">Xy</span><span class="p">,</span>
                    <span class="n">lambd</span><span class="o">=</span><span class="n">lambd</span><span class="p">,</span>
                    <span class="n">psi</span><span class="o">=</span><span class="n">psi</span><span class="p">,</span>
                    <span class="n">starting_values</span><span class="o">=</span><span class="n">beta_ridge</span><span class="p">,</span>
                    <span class="n">sqrt</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sqrt</span><span class="p">,</span>
                    <span class="n">fit_intercept</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">fit_intercept</span><span class="p">,</span>
                    <span class="n">max_iter</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cd_max_iter</span><span class="p">,</span>
                    <span class="n">opt_tol</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cd_tol</span><span class="p">,</span>
                    <span class="n">zero_tol</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">zero_tol</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">beta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cvxpy_solver</span><span class="p">(</span>
                    <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span>
                    <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
                    <span class="n">lambd</span><span class="o">=</span><span class="n">lambd</span><span class="p">,</span>
                    <span class="n">psi</span><span class="o">=</span><span class="n">psi</span><span class="p">,</span>
                    <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span>
                    <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">,</span>
                <span class="p">)</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span><span class="p">:</span>
                <span class="n">beta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_post_lasso</span><span class="p">(</span><span class="n">beta</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

            <span class="c1"># rescale beta</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">prestd</span><span class="p">:</span>
                <span class="n">beta</span> <span class="o">*=</span> <span class="n">y_std</span> <span class="o">/</span> <span class="n">X_std</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">intercept_</span> <span class="o">=</span> <span class="n">y_mean</span> <span class="o">-</span> <span class="n">X_mean</span> <span class="o">@</span> <span class="n">beta</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit_intercept</span> <span class="k">else</span> <span class="mf">0.0</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">nonzero_idx_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">beta</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span> <span class="o">=</span> <span class="n">beta</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_iter_</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">lambd_</span> <span class="o">=</span> <span class="n">lambd</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">psi_</span> <span class="o">=</span> <span class="n">psi</span>

            <span class="k">return</span>

        <span class="c1"># calculate error based on initial</span>
        <span class="c1"># highly correlated vars</span>
        <span class="n">r</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">p</span><span class="p">):</span>
            <span class="n">r</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">st</span><span class="o">.</span><span class="n">pearsonr</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="n">k</span><span class="p">],</span> <span class="n">y</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>

        <span class="n">X_top</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">r</span><span class="p">)[</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">n_corr</span> <span class="p">:]]</span>
        <span class="n">beta0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_OLS</span><span class="p">(</span><span class="n">X_top</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">v</span> <span class="o">=</span> <span class="n">y</span> <span class="o">-</span> <span class="n">X_top</span> <span class="o">@</span> <span class="n">beta0</span>
        <span class="n">s1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">v</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>

        <span class="n">psi</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_psi_calc</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">v</span><span class="o">=</span><span class="n">v</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
        <span class="n">lambd</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lambd_calc</span><span class="p">(</span>
            <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span>
            <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">,</span>
            <span class="n">v</span><span class="o">=</span><span class="n">v</span><span class="p">,</span>
            <span class="n">s1</span><span class="o">=</span><span class="n">s1</span><span class="p">,</span>
            <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span>
            <span class="n">psi</span><span class="o">=</span><span class="n">psi</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># get initial estimates k=0</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">solver</span> <span class="o">==</span> <span class="s2">&quot;cd&quot;</span><span class="p">:</span>
            <span class="n">beta_ridge</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_starting_values</span><span class="p">(</span><span class="n">XX</span><span class="p">,</span> <span class="n">Xy</span><span class="p">,</span> <span class="n">lambd</span><span class="p">,</span> <span class="n">psi</span><span class="p">)</span>
            <span class="n">beta</span> <span class="o">=</span> <span class="n">_cd_solver</span><span class="p">(</span>
                <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span>
                <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
                <span class="n">XX</span><span class="o">=</span><span class="n">XX</span><span class="p">,</span>
                <span class="n">Xy</span><span class="o">=</span><span class="n">Xy</span><span class="p">,</span>
                <span class="n">lambd</span><span class="o">=</span><span class="n">lambd</span><span class="p">,</span>
                <span class="n">psi</span><span class="o">=</span><span class="n">psi</span><span class="p">,</span>
                <span class="n">starting_values</span><span class="o">=</span><span class="n">beta_ridge</span><span class="p">,</span>
                <span class="n">sqrt</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sqrt</span><span class="p">,</span>
                <span class="n">fit_intercept</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">fit_intercept</span><span class="p">,</span>
                <span class="n">max_iter</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cd_max_iter</span><span class="p">,</span>
                <span class="n">opt_tol</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cd_tol</span><span class="p">,</span>
                <span class="n">zero_tol</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">zero_tol</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="n">beta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cvxpy_solver</span><span class="p">(</span>
                <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span>
                <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
                <span class="n">lambd</span><span class="o">=</span><span class="n">lambd</span><span class="p">,</span>
                <span class="n">psi</span><span class="o">=</span><span class="n">psi</span><span class="p">,</span>
                <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span>
                <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="p">):</span>

            <span class="n">s0</span> <span class="o">=</span> <span class="n">s1</span>

            <span class="c1"># post lasso handling</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">lasso_psi</span><span class="p">:</span>
                <span class="n">beta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_post_lasso</span><span class="p">(</span><span class="n">beta</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

            <span class="c1"># error refinement</span>
            <span class="n">v</span> <span class="o">=</span> <span class="n">y</span> <span class="o">-</span> <span class="n">X</span> <span class="o">@</span> <span class="n">beta</span>
            <span class="n">s1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">v</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>

            <span class="c1"># if convergence not reached get new estimates of lambd and psi</span>
            <span class="n">psi</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_psi_calc</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">v</span><span class="o">=</span><span class="n">v</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
            <span class="n">lambd</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lambd_calc</span><span class="p">(</span>
                <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span>
                <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">,</span>
                <span class="n">v</span><span class="o">=</span><span class="n">v</span><span class="p">,</span>
                <span class="n">s1</span><span class="o">=</span><span class="n">s1</span><span class="p">,</span>
                <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span>
                <span class="n">psi</span><span class="o">=</span><span class="n">psi</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">solver</span> <span class="o">==</span> <span class="s2">&quot;cd&quot;</span><span class="p">:</span>
                <span class="n">beta</span> <span class="o">=</span> <span class="n">_cd_solver</span><span class="p">(</span>
                    <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span>
                    <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
                    <span class="n">XX</span><span class="o">=</span><span class="n">XX</span><span class="p">,</span>
                    <span class="n">Xy</span><span class="o">=</span><span class="n">Xy</span><span class="p">,</span>
                    <span class="n">lambd</span><span class="o">=</span><span class="n">lambd</span><span class="p">,</span>
                    <span class="n">psi</span><span class="o">=</span><span class="n">psi</span><span class="p">,</span>
                    <span class="n">starting_values</span><span class="o">=</span><span class="n">beta_ridge</span><span class="p">,</span>
                    <span class="n">sqrt</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sqrt</span><span class="p">,</span>
                    <span class="n">fit_intercept</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">fit_intercept</span><span class="p">,</span>
                    <span class="n">max_iter</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cd_max_iter</span><span class="p">,</span>
                    <span class="n">opt_tol</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cd_tol</span><span class="p">,</span>
                    <span class="n">zero_tol</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">zero_tol</span><span class="p">,</span>
                <span class="p">)</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="n">beta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cvxpy_solver</span><span class="p">(</span>
                    <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span>
                    <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
                    <span class="n">lambd</span><span class="o">=</span><span class="n">lambd</span><span class="p">,</span>
                    <span class="n">psi</span><span class="o">=</span><span class="n">psi</span><span class="p">,</span>
                    <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span>
                    <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">,</span>
                <span class="p">)</span>

            <span class="c1"># check convergence</span>
            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">s1</span> <span class="o">-</span> <span class="n">s0</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_tol</span><span class="p">:</span>
                <span class="k">break</span>
        <span class="c1"># end of algorithm</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">post</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">lasso_psi</span><span class="p">:</span>
            <span class="n">beta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_post_lasso</span><span class="p">(</span><span class="n">beta</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

        <span class="c1"># rescale beta if standardized</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">prestd</span><span class="p">:</span>
            <span class="n">beta</span> <span class="o">*=</span> <span class="n">y_std</span> <span class="o">/</span> <span class="n">X_std</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">intercept_</span> <span class="o">=</span> <span class="n">y_mean</span> <span class="o">-</span> <span class="n">X_mean</span> <span class="o">@</span> <span class="n">beta</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit_intercept</span> <span class="k">else</span> <span class="mf">0.0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nonzero_idx_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">beta</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span> <span class="o">=</span> <span class="n">beta</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_iter_</span> <span class="o">=</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lambd_</span> <span class="o">=</span> <span class="n">lambd</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">psi_</span> <span class="o">=</span> <span class="n">psi</span>

<div class="viewcode-block" id="Rlasso.fit"><a class="viewcode-back" href="../../generated/rlassomodels.Rlasso.html#rlassomodels.Rlasso.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">nopen_idx</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Fit the model to the data.</span>

<span class="sd">        parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X: array-like, shape (n_samples, n_features)</span>
<span class="sd">            Design matrix.</span>
<span class="sd">        y: array-like, shape (n_samples,)</span>
<span class="sd">            Target vector.</span>

<span class="sd">        returns</span>
<span class="sd">        -------</span>
<span class="sd">        self: object</span>
<span class="sd">            Returns self.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># store feature names if dataset is pandas</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">feature_names_</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">columns</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">nopen_idx</span><span class="o">=</span><span class="n">nopen_idx</span><span class="p">)</span>

        <span class="c1"># sklearn estimator must return self</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="Rlasso.fit_formula"><a class="viewcode-back" href="../../generated/rlassomodels.Rlasso.html#rlassomodels.Rlasso.fit_formula">[docs]</a>    <span class="k">def</span> <span class="nf">fit_formula</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">formula</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Fit the the model to the data using fomula language.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        formula: str</span>
<span class="sd">            Formula to fit the model. Ex: &quot;y ~ x1 + x2 + x3&quot;</span>
<span class="sd">        data: Union[pandas.DataFrame, numpy.recarray, dict]</span>
<span class="sd">            Dataset to fit the model.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self: object</span>
<span class="sd">            Returns self.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">y</span><span class="p">,</span> <span class="n">X</span> <span class="o">=</span> <span class="n">dmatrices</span><span class="p">(</span><span class="n">formula</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">feature_names_in_</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">design_info</span><span class="o">.</span><span class="n">column_names</span>

        <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
        <span class="c1"># check if intercept is in data</span>
        <span class="k">if</span> <span class="s2">&quot;Intercept&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_names_in_</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit_intercept</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="p">(</span>
                        <span class="s2">&quot;Intercept is in data but fit_intercept is False.&quot;</span>
                        <span class="s2">&quot; Set fit_intercept to True to fit intercept or&quot;</span>
                        <span class="s2">&quot; update the formula to remove the intercept&quot;</span>
                    <span class="p">)</span>
                <span class="p">)</span>
            <span class="c1"># drop column of ones from X</span>
            <span class="c1"># since intercept calculated in _fit</span>
            <span class="c1"># by partialing out</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="c1"># sklearn estimator must return self</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="Rlasso.predict"><a class="viewcode-back" href="../../generated/rlassomodels.Rlasso.html#rlassomodels.Rlasso.predict">[docs]</a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Use fitted model to predict on new data.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X: array-like, shape (n_samples, n_features)</span>
<span class="sd">            Design matrix.</span>

<span class="sd">        returns</span>
<span class="sd">        -------</span>
<span class="sd">        y_pred: array-like, shape (n_samples,)</span>
<span class="sd">            Predicted target values.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># check if fitted</span>
        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">intercept_</span> <span class="o">+</span> <span class="n">X</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span></div></div>


<div class="viewcode-block" id="RlassoLogit"><a class="viewcode-back" href="../../generated/rlassomodels.RlassoLogit.html#rlassomodels.RlassoLogit">[docs]</a><span class="k">class</span> <span class="nc">RlassoLogit</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">ClassifierMixin</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">post</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">fit_intercept</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">c</span><span class="o">=</span><span class="mf">1.1</span><span class="p">,</span>
        <span class="n">gamma</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span>
        <span class="n">zero_tol</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span>
        <span class="n">solver_opts</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Rigorous Lasso Logistic Regression.&quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">post</span> <span class="o">=</span> <span class="n">post</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fit_intercept</span> <span class="o">=</span> <span class="n">fit_intercept</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">c</span> <span class="o">=</span> <span class="n">c</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">gamma</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">zero_tol</span> <span class="o">=</span> <span class="n">zero_tol</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">solver_opts</span> <span class="o">=</span> <span class="n">solver_opts</span>

    <span class="k">def</span> <span class="nf">_criterion_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">lambd</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">regularization</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Criterion function for the penalized Lasso Logistic Regression.&quot;&quot;&quot;</span>

        <span class="n">ll</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">cp</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">X</span> <span class="o">@</span> <span class="n">beta</span><span class="p">)</span> <span class="o">-</span> <span class="n">cp</span><span class="o">.</span><span class="n">logistic</span><span class="p">(</span><span class="n">X</span> <span class="o">@</span> <span class="n">beta</span><span class="p">))</span> <span class="o">/</span> <span class="n">n</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">regularization</span><span class="p">:</span>
            <span class="k">return</span> <span class="o">-</span><span class="n">ll</span>
        <span class="n">reg</span> <span class="o">=</span> <span class="p">(</span><span class="n">lambd</span> <span class="o">/</span> <span class="n">n</span><span class="p">)</span> <span class="o">*</span> <span class="n">cp</span><span class="o">.</span><span class="n">norm1</span><span class="p">(</span><span class="n">beta</span><span class="p">)</span>
        <span class="k">return</span> <span class="o">-</span><span class="p">(</span><span class="n">ll</span> <span class="o">-</span> <span class="n">reg</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_cvxpy_solve</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">lambd</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Solve the problem using cvxpy.&quot;&quot;&quot;</span>

        <span class="n">beta</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
        <span class="n">obj</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">Minimize</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_criterion_function</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">lambd</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>
        <span class="n">prob</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">Problem</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span>

        <span class="c1"># solve problem and return beta</span>
        <span class="n">prob</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">solver_opts</span> <span class="ow">or</span> <span class="p">{})</span>
        <span class="n">beta</span> <span class="o">=</span> <span class="n">beta</span><span class="o">.</span><span class="n">value</span>
        <span class="n">beta</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">beta</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">zero_tol</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>

        <span class="k">return</span> <span class="n">beta</span>

    <span class="k">def</span> <span class="nf">_decision_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">beta</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Compute the decision function of the model.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">X</span> <span class="o">@</span> <span class="n">beta</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">_lambd_calc</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
        <span class="n">lambd0</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">c</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="o">*</span> <span class="n">st</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">p</span><span class="p">))</span>
        <span class="n">lambd</span> <span class="o">=</span> <span class="n">lambd0</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">n</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">lambd0</span><span class="p">,</span> <span class="n">lambd</span>

    <span class="k">def</span> <span class="nf">_fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>

        <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>

        <span class="k">if</span> <span class="n">gamma</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">gamma</span> <span class="o">=</span> <span class="mf">0.1</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>

        <span class="n">lambd0</span><span class="p">,</span> <span class="n">lambd</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lambd_calc</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>

        <span class="n">beta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cvxpy_solve</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">lambd</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>

        <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;beta&quot;</span><span class="p">:</span> <span class="n">beta</span><span class="p">,</span> <span class="s2">&quot;lambd0&quot;</span><span class="p">:</span> <span class="n">lambd0</span><span class="p">,</span> <span class="s2">&quot;lambd&quot;</span><span class="p">:</span> <span class="n">lambd</span><span class="p">}</span>

<div class="viewcode-block" id="RlassoLogit.fit"><a class="viewcode-back" href="../../generated/rlassomodels.RlassoLogit.html#rlassomodels.RlassoLogit.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Fit the model to the data.</span>

<span class="sd">        parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X: array-like, shape (n_samples, n_features)</span>
<span class="sd">            Design matrix.</span>
<span class="sd">        y: array-like, shape (n_samples,)</span>
<span class="sd">            Target vector.</span>
<span class="sd">        gamma: float, optional (default: 0.1 / np.log(n_samples))</span>

<span class="sd">        returns</span>
<span class="sd">        -------</span>
<span class="sd">        self: object</span>
<span class="sd">            Returns self.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># check inputs</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">check_X_y</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">accept_sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># assert y is binary</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;y must be binary&quot;</span><span class="p">)</span>

        <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="n">gamma</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span> <span class="o">=</span> <span class="n">res</span><span class="p">[</span><span class="s2">&quot;beta&quot;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lambd0_</span> <span class="o">=</span> <span class="n">res</span><span class="p">[</span><span class="s2">&quot;lambd0&quot;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lambd_</span> <span class="o">=</span> <span class="n">res</span><span class="p">[</span><span class="s2">&quot;lambd&quot;</span><span class="p">]</span>

        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="RlassoLogit.predict"><a class="viewcode-back" href="../../generated/rlassomodels.RlassoLogit.html#rlassomodels.RlassoLogit.predict">[docs]</a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Predict the class labels for X.&quot;&quot;&quot;</span>
        <span class="c1"># check model is fitted and inputs are correct</span>
        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;coef_&quot;</span><span class="p">])</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="n">probas</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_decision_function</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">probas</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span></div>

<div class="viewcode-block" id="RlassoLogit.predict_proba"><a class="viewcode-back" href="../../generated/rlassomodels.RlassoLogit.html#rlassomodels.RlassoLogit.predict_proba">[docs]</a>    <span class="k">def</span> <span class="nf">predict_proba</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Predict class probabilities for X.&quot;&quot;&quot;</span>
        <span class="c1"># check model is fitted and inputs are correct</span>
        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_decision_function</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span></div>

<div class="viewcode-block" id="RlassoLogit.predict_log_proba"><a class="viewcode-back" href="../../generated/rlassomodels.RlassoLogit.html#rlassomodels.RlassoLogit.predict_log_proba">[docs]</a>    <span class="k">def</span> <span class="nf">predict_log_proba</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Predict class log-probabilities for X.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_decision_function</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span><span class="p">))</span></div></div>


<div class="viewcode-block" id="RlassoIV"><a class="viewcode-back" href="../../generated/rlassomodels.RlassoIV.html#rlassomodels.RlassoIV">[docs]</a><span class="k">class</span> <span class="nc">RlassoIV</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Rigorous Lasso for instrumental-variable estimation in</span>
<span class="sd">    the presence of high-dimensional instruments and/or</span>
<span class="sd">    controls. Uses the post-double-selection (PDS) and</span>
<span class="sd">    post-regularization (CHS) methods for estimation, see</span>
<span class="sd">    references below.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    select_X: bool, optional (default: True)</span>
<span class="sd">        Whether to use lasso/post-lasso for feature</span>
<span class="sd">        selection of high-dim controls.</span>

<span class="sd">    select_Z: bool, optional (default: True)</span>
<span class="sd">        Whether to use lasso/post-lasso for feature</span>
<span class="sd">        selection of high-dim instruments.</span>

<span class="sd">    post: bool, default=True</span>
<span class="sd">        If True, post-lasso is used to estimate betas,</span>
<span class="sd">        meaning that features selected by rlasso are</span>
<span class="sd">        estimated by OLS in the final model, as outlined</span>
<span class="sd">        in [2]_.</span>

<span class="sd">    sqrt: bool, default=False</span>
<span class="sd">        If True, square-root lasso criterion is minimized</span>
<span class="sd">        is minimized instead of normal lasso. See [1]_ and</span>
<span class="sd">        notes below for details.</span>

<span class="sd">    fit_intercept: bool, default=True</span>
<span class="sd">        If True, an unpenalized intercept is estimated</span>
<span class="sd">        by mean centering the data prior to estimation.</span>

<span class="sd">    cov_type: str, default=&quot;nonrobust&quot;</span>
<span class="sd">        Type of covariance matrix. Right now the</span>
<span class="sd">        supported types are: &quot;nonrobust&quot;, &quot;robust&quot;.</span>

<span class="sd">    x_dependent: bool, default=False</span>
<span class="sd">        If True, the alternative and less conservative lambda</span>
<span class="sd">        is estimated by simulation using the conditional</span>
<span class="sd">        distribution of the design matrix.</span>

<span class="sd">    n_sim: int, default=5000</span>
<span class="sd">        Number of simulations to be performed for x-dependent</span>
<span class="sd">        lambda calculation.</span>

<span class="sd">    random_state: int, default=None</span>
<span class="sd">        Random seed used for simulations if `x_dependent` is</span>
<span class="sd">        set to `True`.</span>

<span class="sd">    lasso_psi: bool, default=False</span>
<span class="sd">        By default post-lasso is the default method for obtaining</span>
<span class="sd">        residuals in the</span>

<span class="sd">    prestd: bool, default=False</span>
<span class="sd">        If True, the data is prestandardized instead of</span>
<span class="sd">        on the fly by penalty loadings. Currently only</span>
<span class="sd">        supports homoscedastic case.</span>

<span class="sd">    n_corr: int, default=5</span>
<span class="sd">        Number of most correlated variables to be used in the</span>
<span class="sd">        for initial calculation of the residuals.</span>

<span class="sd">    c: float, default=1.1</span>
<span class="sd">        Slack parameter used in the lambda calculation. From</span>
<span class="sd">        [3]_ &quot;c needs to be greater than 1 for the regularization</span>
<span class="sd">        event to hold asymptotically, but not too high as the</span>
<span class="sd">        shrinkage bias is increasing in c.&quot;</span>

<span class="sd">    gamma: float, optional=None</span>
<span class="sd">        Regularization parameter, where the probability of</span>
<span class="sd">        selecting the correct model is given by 1-gamma.</span>
<span class="sd">        If not specified, the the value is set to:</span>
<span class="sd">        0.1 / np.log(n)</span>

<span class="sd">    max_iter: int, default=2</span>
<span class="sd">        Maximum number of iterations to perform in the iterative</span>
<span class="sd">        estimation procedure to obtain the Rlasso estimates.</span>

<span class="sd">    conv_tol: float, default=1e-4</span>
<span class="sd">        Tolerance for the convergence of the iterative estimation</span>
<span class="sd">        procedure.</span>

<span class="sd">    solver: str, default=&quot;cd&quot;</span>
<span class="sd">        Solver to be used for the iterative estimation procedure.</span>
<span class="sd">        Alternatives are:</span>
<span class="sd">        &quot;cd&quot; - coordinate descent method.</span>
<span class="sd">        &quot;cvxpy&quot; - cvxpy solver.</span>

<span class="sd">    cd_max_iter: int, default=10000</span>
<span class="sd">        Maximum number of iterations to be perform by the coordinate</span>
<span class="sd">        descent algorithm before stopping.</span>

<span class="sd">    cd_tol: float, default=1e-10</span>
<span class="sd">        Convergence tolerance for the coordinate descent algorithm.</span>

<span class="sd">    cvxpy_opts: dict, default=None</span>
<span class="sd">        Additional options to be passed to the cvxpy solver. See cvxpy</span>
<span class="sd">        documentation for more details:</span>
<span class="sd">        https://www.cvxpy.org/tutorial/advanced/index.html#solve-method-options</span>

<span class="sd">    zero_tol: float, default=1e-4</span>
<span class="sd">        Tolerance for the rounding of estimated coefficients to zero.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    results_: dict[&quot;PDS&quot;, &quot;CHS&quot;]</span>
<span class="sd">        Dictionary containing the 2-stage-least-squares estimates.</span>
<span class="sd">        Values are `linearmodels.iv.IV2SLS` objects. See:</span>
<span class="sd">        https://bashtage.github.io/linearmodels/iv/iv/linearmodels.iv.model.IV2SLS.html</span>
<span class="sd">        https://bashtage.github.io/linearmodels/iv/examples/basic-examples.html</span>

<span class="sd">    X_selected_: dict[list[str]]</span>
<span class="sd">        List of selected controls for each stage in the estimation.</span>

<span class="sd">    Z_selected_: list[str]</span>
<span class="sd">        List of selected instruments.</span>

<span class="sd">    valid_vars_: list[str]</span>
<span class="sd">        List of variables for which standard errors and test</span>
<span class="sd">        statistics are valid.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] Chernozhukov, V., Hansen, C., &amp; Spindler, M. (2015).</span>
<span class="sd">        Post-selection and post-regularization inference in linear models with many controls and instruments.</span>
<span class="sd">        American Economic Review, 105(5), 486-90.</span>

<span class="sd">    .. [2] Belloni, A., Chernozhukov, V., &amp; Hansen, C. (2014).</span>
<span class="sd">        Inference on treatment effects after selection among high-dimensional controls.</span>
<span class="sd">        The Review of Economic Studies, 81(2), 608-650.</span>

<span class="sd">    .. [3] Ahrens, A., Hansen, C. B., &amp; Schaffer, M. (2019).</span>
<span class="sd">        PDSLASSO: Stata module for post-selection and</span>
<span class="sd">        post-regularization OLS or IV estimation and inference.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    ``RlassoIV`` is used when one wants to use instruments in order to</span>
<span class="sd">    estimate low-dimensional endogenous variables in the setting</span>

<span class="sd">    .. math:: y_{i}=\\alpha d_{i}+x_{i}^{\prime} \\beta+\\varepsilon_{i}</span>
<span class="sd">    .. math:: d_{i}=x_{i}^{\prime} \gamma+z_{i}^{\prime} \delta+u_{i}</span>

<span class="sd">    where :math:`d_{i}` is endogonous and `both instruments $z_i$ and and</span>
<span class="sd">    controls $x_i$ are possibily high-dimensional.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from rlassomodels import RlassoIV</span>
<span class="sd">    &gt;&gt;&gt; X = np.random.randn(100, 20)</span>
<span class="sd">    &gt;&gt;&gt; Z = np.random.randn(100, 15)</span>
<span class="sd">    &gt;&gt;&gt; d_endog = np.random.randn(100)</span>
<span class="sd">    &gt;&gt;&gt; y = np.random.randn(100)</span>
<span class="sd">    &gt;&gt;&gt; # Fit the model, use rlasso to select both controls and instruments</span>
<span class="sd">    &gt;&gt;&gt; rlasso_iv = RlassoIV(select_X=True, select_Z=True)</span>
<span class="sd">    &gt;&gt;&gt; rlasso_iv.fit(X, y, D_exog = None, D_endog=d_endog, Z=Z)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">select_X</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">select_Z</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">post</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">sqrt</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">fit_intercept</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">cov_type</span><span class="o">=</span><span class="s2">&quot;nonrobust&quot;</span><span class="p">,</span>
        <span class="n">x_dependent</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">lasso_psi</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">prestd</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">n_corr</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
        <span class="n">max_iter</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="n">conv_tol</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span>
        <span class="n">n_sim</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span>
        <span class="n">c</span><span class="o">=</span><span class="mf">1.1</span><span class="p">,</span>
        <span class="n">gamma</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">solver</span><span class="o">=</span><span class="s2">&quot;cd&quot;</span><span class="p">,</span>
        <span class="n">cd_max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
        <span class="n">cd_tol</span><span class="o">=</span><span class="mf">1e-10</span><span class="p">,</span>
        <span class="n">cvxpy_opts</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">zero_tol</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span>
    <span class="p">):</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">select_X</span> <span class="o">=</span> <span class="n">select_X</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">select_Z</span> <span class="o">=</span> <span class="n">select_Z</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">post</span> <span class="o">=</span> <span class="n">post</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sqrt</span> <span class="o">=</span> <span class="n">sqrt</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fit_intercept</span> <span class="o">=</span> <span class="n">fit_intercept</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cov_type</span> <span class="o">=</span> <span class="n">cov_type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">x_dependent</span> <span class="o">=</span> <span class="n">x_dependent</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lasso_psi</span> <span class="o">=</span> <span class="n">lasso_psi</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prestd</span> <span class="o">=</span> <span class="n">prestd</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_corr</span> <span class="o">=</span> <span class="n">n_corr</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_sim</span> <span class="o">=</span> <span class="n">n_sim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">c</span> <span class="o">=</span> <span class="n">c</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">gamma</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span> <span class="o">=</span> <span class="n">max_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv_tol</span> <span class="o">=</span> <span class="n">conv_tol</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">solver</span> <span class="o">=</span> <span class="n">solver</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cd_max_iter</span> <span class="o">=</span> <span class="n">cd_max_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cd_tol</span> <span class="o">=</span> <span class="n">cd_tol</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">zero_tol</span> <span class="o">=</span> <span class="n">zero_tol</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cvxpy_opts</span> <span class="o">=</span> <span class="n">cvxpy_opts</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">rlasso</span> <span class="o">=</span> <span class="n">Rlasso</span><span class="p">(</span>
            <span class="n">post</span><span class="o">=</span><span class="n">post</span><span class="p">,</span>
            <span class="n">sqrt</span><span class="o">=</span><span class="n">sqrt</span><span class="p">,</span>
            <span class="n">fit_intercept</span><span class="o">=</span><span class="n">fit_intercept</span><span class="p">,</span>
            <span class="n">cov_type</span><span class="o">=</span><span class="n">cov_type</span><span class="p">,</span>
            <span class="n">x_dependent</span><span class="o">=</span><span class="n">x_dependent</span><span class="p">,</span>
            <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span>
            <span class="n">lasso_psi</span><span class="o">=</span><span class="n">lasso_psi</span><span class="p">,</span>
            <span class="n">prestd</span><span class="o">=</span><span class="n">prestd</span><span class="p">,</span>
            <span class="n">n_corr</span><span class="o">=</span><span class="n">n_corr</span><span class="p">,</span>
            <span class="n">n_sim</span><span class="o">=</span><span class="n">n_sim</span><span class="p">,</span>
            <span class="n">c</span><span class="o">=</span><span class="n">c</span><span class="p">,</span>
            <span class="n">gamma</span><span class="o">=</span><span class="n">gamma</span><span class="p">,</span>
            <span class="n">max_iter</span><span class="o">=</span><span class="n">max_iter</span><span class="p">,</span>
            <span class="n">conv_tol</span><span class="o">=</span><span class="n">conv_tol</span><span class="p">,</span>
            <span class="n">solver</span><span class="o">=</span><span class="n">solver</span><span class="p">,</span>
            <span class="n">cd_max_iter</span><span class="o">=</span><span class="n">cd_max_iter</span><span class="p">,</span>
            <span class="n">cd_tol</span><span class="o">=</span><span class="n">cd_tol</span><span class="p">,</span>
            <span class="n">cvxpy_opts</span><span class="o">=</span><span class="n">cvxpy_opts</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_check_inputs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">D_exog</span><span class="p">,</span> <span class="n">D_endog</span><span class="p">,</span> <span class="n">Z</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Checks inputs before passed to fit. For now, data is</span>
<span class="sd">        converted to pd.DataFrame&#39;s as it simplifices keeping track</span>
<span class="sd">        of nonzero indices and varnames significantly.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">def</span> <span class="nf">_check_single</span><span class="p">(</span><span class="n">var</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">var</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">return</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">var</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">var</span>

            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">var</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
                <span class="n">var</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">var</span><span class="p">)</span>
                <span class="n">var</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">}{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">var</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])]</span>
                <span class="k">return</span> <span class="n">var</span>

            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">var</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">series</span><span class="o">.</span><span class="n">Series</span><span class="p">):</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">var</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">var</span><span class="o">.</span><span class="n">name</span>
                    <span class="k">else</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">var</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">])</span>
                <span class="p">)</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> must be a pandas dataframe or numpy array&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">var</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>

        <span class="n">X</span> <span class="o">=</span> <span class="n">_check_single</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">_check_single</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="s2">&quot;y&quot;</span><span class="p">)</span>
        <span class="n">D_exog</span> <span class="o">=</span> <span class="n">_check_single</span><span class="p">(</span><span class="n">D_exog</span><span class="p">,</span> <span class="s2">&quot;d_exog&quot;</span><span class="p">)</span>
        <span class="n">D_endog</span> <span class="o">=</span> <span class="n">_check_single</span><span class="p">(</span><span class="n">D_endog</span><span class="p">,</span> <span class="s2">&quot;d_endog&quot;</span><span class="p">)</span>
        <span class="n">Z</span> <span class="o">=</span> <span class="n">_check_single</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="s2">&quot;Z&quot;</span><span class="p">)</span>

        <span class="c1"># save valid inference variables</span>
        <span class="n">valid_vars</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="n">D_exog</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">valid_vars</span> <span class="o">+=</span> <span class="nb">list</span><span class="p">(</span><span class="n">D_exog</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
        <span class="k">if</span> <span class="n">D_endog</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">valid_vars</span> <span class="o">+=</span> <span class="nb">list</span><span class="p">(</span><span class="n">D_endog</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>

        <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">D_exog</span><span class="p">,</span> <span class="n">D_endog</span><span class="p">,</span> <span class="n">Z</span><span class="p">,</span> <span class="n">valid_vars</span>

    <span class="k">def</span> <span class="nf">_select_hd_vars</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">regressors</span><span class="p">,</span> <span class="n">depvar</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Selects high-dimensional variables from the regressors.</span>
<span class="sd">        Returns nonzero idx, residuals and fitted values.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">depvar</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">selected</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">resid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">))</span>
        <span class="n">fitted</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">))</span>

        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">p</span><span class="p">):</span>
            <span class="n">reg</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rlasso</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">regressors</span><span class="p">,</span> <span class="n">depvar</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="n">j</span><span class="p">])</span>
            <span class="p">[</span><span class="n">selected</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">regressors</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="n">reg</span><span class="o">.</span><span class="n">nonzero_idx_</span><span class="p">]</span><span class="o">.</span><span class="n">columns</span><span class="p">]</span>
            <span class="n">pred</span> <span class="o">=</span> <span class="n">reg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">regressors</span><span class="p">)</span>
            <span class="n">resid</span><span class="p">[:,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">depvar</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="n">j</span><span class="p">]</span> <span class="o">-</span> <span class="n">pred</span>
            <span class="n">fitted</span><span class="p">[:,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">pred</span>

        <span class="n">resid</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">resid</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">depvar</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
        <span class="n">fitted</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">fitted</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">depvar</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
        <span class="c1"># return unique selected variables</span>
        <span class="n">selected</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">selected</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">selected</span><span class="p">,</span> <span class="n">resid</span><span class="p">,</span> <span class="n">fitted</span>

    <span class="k">def</span> <span class="nf">_partial_ld_vars</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">regressors</span><span class="p">,</span> <span class="n">depvar</span><span class="p">):</span>

        <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">depvar</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">resid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">))</span>
        <span class="n">fitted</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">))</span>

        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">p</span><span class="p">):</span>
            <span class="n">tmp_dep</span> <span class="o">=</span> <span class="n">depvar</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
            <span class="n">tmp_regressors</span> <span class="o">=</span> <span class="n">regressors</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
            <span class="n">beta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rlasso</span><span class="o">.</span><span class="n">_OLS</span><span class="p">(</span><span class="n">tmp_regressors</span><span class="p">,</span> <span class="n">tmp_dep</span><span class="p">)</span>
            <span class="n">pred</span> <span class="o">=</span> <span class="n">tmp_dep</span> <span class="o">-</span> <span class="n">tmp_regressors</span> <span class="o">@</span> <span class="n">beta</span>
            <span class="n">fitted</span><span class="p">[:,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">pred</span>
            <span class="n">resid</span><span class="p">[:,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">depvar</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="n">j</span><span class="p">]</span> <span class="o">-</span> <span class="n">pred</span>

        <span class="n">resid</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">resid</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">depvar</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
        <span class="n">fitted</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">fitted</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">depvar</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">resid</span><span class="p">,</span> <span class="n">fitted</span>

<div class="viewcode-block" id="RlassoIV.fit"><a class="viewcode-back" href="../../generated/rlassomodels.RlassoIV.html#rlassomodels.RlassoIV.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">X</span><span class="p">,</span>
        <span class="n">y</span><span class="p">,</span>
        <span class="n">D_exog</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">D_endog</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">Z</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Fit the model.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X: array-like, shape (n_samples, n_controls)</span>
<span class="sd">            Control variables. Potentially high-dimensional.</span>

<span class="sd">        y: array-like, shape (n_samples,)</span>
<span class="sd">            Outcome/dependent variable.</span>

<span class="sd">        D_exog: array-like, shape (n_samples, n_exog)</span>
<span class="sd">            Low-dimensionnal exogenous regressors. On which inference</span>
<span class="sd">            is performed.</span>

<span class="sd">        D_endog: array-like, shape (n_samples, n_endog)</span>
<span class="sd">            Endogenous regressors. On which inference</span>
<span class="sd">            is performed.</span>

<span class="sd">        Z: array-like, shape (n_samples, n_instruments)</span>
<span class="sd">            Instruments. Potentially high-dimensional.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self : object</span>
<span class="sd">            Returns the instance itself.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">select_Z</span> <span class="ow">and</span> <span class="n">Z</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;`select_Z=True` but no instruments `Z` provided&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">Z</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">D_endog</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Endogenous regressors D_endog must be provided&quot;</span><span class="p">)</span>

        <span class="c1"># check inputs</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">D_exog</span><span class="p">,</span> <span class="n">D_endog</span><span class="p">,</span> <span class="n">Z</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">valid_vars_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_inputs</span><span class="p">(</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">D_exog</span><span class="p">,</span> <span class="n">D_endog</span><span class="p">,</span> <span class="n">Z</span>
        <span class="p">)</span>

        <span class="c1"># if X and not self.select_X and X.shape[1] &gt;= X.shape[0]:</span>
        <span class="c1">#     warnings.warn(&quot;`select_X=False` but X has more variables than observations&quot;)</span>
        <span class="c1">#</span>
        <span class="c1"># if Z and not self.select_Z and Z.shape[1] &gt;= Z.shape[0]:</span>
        <span class="c1">#     warnings.warn(</span>
        <span class="c1">#         &quot;`select_Z=False` but Z has more instruments than observations&quot;</span>
        <span class="c1">#     )</span>

        <span class="c1"># store all the selected variables</span>
        <span class="n">X_selected</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">select_X</span><span class="p">:</span>
            <span class="c1"># X_all_selected = []</span>
            <span class="c1"># step 1 (PDS/CHS). Select HD controls for dep var w.r.t. HD Xs</span>
            <span class="n">X_selected</span><span class="p">[</span><span class="s2">&quot;step_1&quot;</span><span class="p">],</span> <span class="n">rho_y</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_select_hd_vars</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

            <span class="c1"># step 2 (PDS/CHS). Select HD controls for exog regressors w.r.t. HD Xs</span>
            <span class="k">if</span> <span class="n">D_exog</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">X_selected</span><span class="p">[</span><span class="s2">&quot;step_2&quot;</span><span class="p">],</span> <span class="n">rho_d</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_select_hd_vars</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">D_exog</span><span class="p">)</span>

            <span class="c1"># step 3 (PDS). Select HD controls for endog regressors w.r.t. HD Xs</span>
            <span class="k">if</span> <span class="n">D_endog</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">X_selected</span><span class="p">[</span><span class="s2">&quot;step_3&quot;</span><span class="p">],</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_select_hd_vars</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">D_endog</span><span class="p">)</span>

            <span class="c1"># store all the selected X&#39;s</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">X_selected_</span> <span class="o">=</span> <span class="n">X_selected</span>

        <span class="c1"># handle CHS residuals in the case of</span>
        <span class="c1"># X&#39;s not being penalized `select_X=False`</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">rho_y</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_partial_ld_vars</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">D_exog</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">rho_d</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_partial_ld_vars</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">D_exog</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">select_Z</span><span class="p">:</span>
            <span class="c1"># step 5 (PDS/CHS). Select HD controls for Z w.r.t. HD Xs</span>
            <span class="n">Z_selected</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">d_hat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_select_hd_vars</span><span class="p">(</span>
                <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">Z</span><span class="p">,</span> <span class="n">X</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">D_endog</span>
            <span class="p">)</span>
            <span class="n">Z_selected</span> <span class="o">=</span> <span class="p">[</span><span class="n">s</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">Z_selected</span> <span class="k">if</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">Z</span><span class="o">.</span><span class="n">columns</span><span class="p">]</span>
            <span class="n">Z</span> <span class="o">=</span> <span class="n">Z</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">Z_selected</span><span class="p">]</span>
            <span class="c1"># elif D_endog is not None:</span>
            <span class="c1">#     self.X_selected_4_ = self._select_hd_vars(X, Z)</span>
            <span class="c1">#     X_all_selected += self.X_selected_4_</span>

            <span class="c1"># step 6 (CHS). Create optimal instrument for endog</span>
            <span class="n">X_selected</span><span class="p">[</span><span class="s2">&quot;step_6&quot;</span><span class="p">],</span> <span class="n">iv_e</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_select_hd_vars</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">d_hat</span><span class="p">)</span>
            <span class="c1"># iv_e.columns = Z_selected</span>

            <span class="c1"># store all the selected instruments</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">Z_selected_</span> <span class="o">=</span> <span class="n">Z_selected</span>

            <span class="c1"># step 7 (CHS). Create orthogonalized endog</span>
            <span class="n">rho_e</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
                <span class="n">D_endog</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span> <span class="o">-</span> <span class="p">(</span><span class="n">d_hat</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span> <span class="o">-</span> <span class="n">iv_e</span><span class="p">),</span>
                <span class="n">columns</span><span class="o">=</span><span class="n">D_endog</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="c1"># handle CHS residuals in the case of Z&#39;s not being</span>
        <span class="c1"># penalized `select_Z=False`</span>
        <span class="k">elif</span> <span class="n">D_endog</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">d_hat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_partial_ld_vars</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">Z</span><span class="p">,</span> <span class="n">X</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">D_endog</span><span class="p">)</span>

            <span class="n">iv_e</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_partial_ld_vars</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">d_hat</span><span class="p">)</span>

            <span class="c1"># step 7 (CHS). Create orthogonalized endog</span>
            <span class="n">rho_e</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
                <span class="n">D_endog</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span> <span class="o">-</span> <span class="p">(</span><span class="n">d_hat</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span> <span class="o">-</span> <span class="n">iv_e</span><span class="p">),</span>
                <span class="n">columns</span><span class="o">=</span><span class="n">D_endog</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="c1"># adjust for variation in naming for homoscedastic case</span>
        <span class="n">cov_type</span> <span class="o">=</span> <span class="s2">&quot;unadjusted&quot;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cov_type</span> <span class="o">==</span> <span class="s2">&quot;nonrobust&quot;</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">cov_type</span>

        <span class="c1"># fit CHS IV2SLS</span>
        <span class="n">chs</span> <span class="o">=</span> <span class="n">IV2SLS</span><span class="p">(</span>
            <span class="n">rho_y</span><span class="p">,</span>
            <span class="n">rho_d</span> <span class="k">if</span> <span class="s2">&quot;rho_d&quot;</span> <span class="ow">in</span> <span class="nb">locals</span><span class="p">()</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">rho_e</span> <span class="k">if</span> <span class="s2">&quot;rho_e&quot;</span> <span class="ow">in</span> <span class="nb">locals</span><span class="p">()</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">iv_e</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span> <span class="k">if</span> <span class="s2">&quot;iv_e&quot;</span> <span class="ow">in</span> <span class="nb">locals</span><span class="p">()</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
        <span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">cov_type</span><span class="o">=</span><span class="n">cov_type</span><span class="p">)</span>

        <span class="c1"># fit PDS IV2SLS</span>
        <span class="c1"># get unique X selected</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">select_X</span><span class="p">:</span>
            <span class="n">X_unique_mask</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">step</span><span class="p">,</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">X_selected</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="c1"># only for chs</span>
                <span class="k">if</span> <span class="n">step</span> <span class="o">!=</span> <span class="s2">&quot;step_6&quot;</span><span class="p">:</span>
                    <span class="n">X_unique_mask</span> <span class="o">+=</span> <span class="n">var</span>

            <span class="n">X_unique_mask</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">X_unique_mask</span><span class="p">))</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">X_unique_mask</span><span class="p">:</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;No controls in X where selected&quot;</span><span class="p">)</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">X_unique_mask</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">D_exog</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">D_exog</span><span class="p">,</span> <span class="n">X</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit_intercept</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">add_constant</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="n">pds</span> <span class="o">=</span> <span class="n">IV2SLS</span><span class="p">(</span>
            <span class="n">y</span><span class="p">,</span>
            <span class="n">X</span><span class="p">,</span>
            <span class="n">D_endog</span> <span class="k">if</span> <span class="n">D_endog</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">Z</span> <span class="k">if</span> <span class="n">Z</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
        <span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">cov_type</span><span class="o">=</span><span class="n">cov_type</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">results_</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;CHS&quot;</span><span class="p">:</span> <span class="n">chs</span><span class="p">,</span> <span class="s2">&quot;PDS&quot;</span><span class="p">:</span> <span class="n">pds</span><span class="p">}</span>

        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="RlassoIV.summary"><a class="viewcode-back" href="../../generated/rlassomodels.RlassoIV.html#rlassomodels.RlassoIV.summary">[docs]</a>    <span class="k">def</span> <span class="nf">summary</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Produces a summary of the results.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;results_&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">compare</span><span class="p">(</span>
            <span class="p">{</span>
                <span class="s2">&quot;PDS&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">results_</span><span class="p">[</span><span class="s2">&quot;PDS&quot;</span><span class="p">],</span>
                <span class="s2">&quot;CHS&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">results_</span><span class="p">[</span><span class="s2">&quot;CHS&quot;</span><span class="p">],</span>
            <span class="p">},</span>
            <span class="n">stars</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">precision</span><span class="o">=</span><span class="s2">&quot;std_errors&quot;</span><span class="p">,</span>
        <span class="p">)</span></div></div>


<div class="viewcode-block" id="RlassoPDS"><a class="viewcode-back" href="../../generated/rlassomodels.RlassoPDS.html#rlassomodels.RlassoPDS">[docs]</a><span class="k">class</span> <span class="nc">RlassoPDS</span><span class="p">(</span><span class="n">RlassoIV</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Rigorous Lasso for causal inference of low-dimensional</span>
<span class="sd">    exogenous regressors in the presence of high-dimensional</span>
<span class="sd">    controls. Uses the post-double-selection (PDS) and</span>
<span class="sd">    post-regularization (CHS) methods for estimation [1]_, [2]_.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    post: bool, default=True</span>
<span class="sd">        If True, post-lasso is used to estimate betas,</span>
<span class="sd">        meaning that features selected by rlasso are</span>
<span class="sd">        estimated by OLS in the final model, as outlined</span>
<span class="sd">        in [2]_.</span>

<span class="sd">    sqrt: bool, default=False</span>
<span class="sd">        If True, square-root lasso criterion is minimized</span>
<span class="sd">        is minimized instead of normal lasso. See [1]_ and</span>
<span class="sd">        notes below for details.</span>

<span class="sd">    fit_intercept: bool, default=True</span>
<span class="sd">        If True, an unpenalized intercept is estimated</span>
<span class="sd">        by mean centering the data prior to estimation.</span>

<span class="sd">    cov_type: str, default=&quot;nonrobust&quot;</span>
<span class="sd">        Type of covariance matrix. Right now the</span>
<span class="sd">        supported types are: &quot;nonrobust&quot;, &quot;robust&quot;.</span>

<span class="sd">    x_dependent: bool, default=False</span>
<span class="sd">        If True, the alternative and less conservative lambda</span>
<span class="sd">        is estimated by simulation using the conditional</span>
<span class="sd">        distribution of the design matrix.</span>

<span class="sd">    n_sim: int, default=5000</span>
<span class="sd">        Number of simulations to be performed for x-dependent</span>
<span class="sd">        lambda calculation.</span>

<span class="sd">    random_state: int, default=None</span>
<span class="sd">        Random seed used for simulations if `x_dependent` is</span>
<span class="sd">        set to `True`.</span>

<span class="sd">    lasso_psi: bool, default=False</span>
<span class="sd">        By default post-lasso is the default method for obtaining</span>
<span class="sd">        residuals in the</span>

<span class="sd">    prestd: bool, default=False</span>
<span class="sd">        If True, the data is prestandardized instead of</span>
<span class="sd">        on the fly by penalty loadings. Currently only</span>
<span class="sd">        supports homoscedastic case.</span>

<span class="sd">    n_corr: int, default=5</span>
<span class="sd">        Number of most correlated variables to be used in the</span>
<span class="sd">        for initial calculation of the residuals.</span>

<span class="sd">    c: float, default=1.1</span>
<span class="sd">        Slack parameter used in the lambda calculation. From</span>
<span class="sd">        [3]_ &quot;c needs to be greater than 1 for the regularization</span>
<span class="sd">        event to hold asymptotically, but not too high as the</span>
<span class="sd">        shrinkage bias is increasing in c.&quot;</span>

<span class="sd">    gamma: float, optional=None</span>
<span class="sd">        Regularization parameter, where the probability of</span>
<span class="sd">        selecting the correct model is given by 1-gamma.</span>
<span class="sd">        If not specified, the the value is set to:</span>
<span class="sd">        0.1 / np.log(n)</span>

<span class="sd">    max_iter: int, default=2</span>
<span class="sd">        Maximum number of iterations to perform in the iterative</span>
<span class="sd">        estimation procedure to obtain the Rlasso estimates.</span>

<span class="sd">    conv_tol: float, default=1e-4</span>
<span class="sd">        Tolerance for the convergence of the iterative estimation</span>
<span class="sd">        procedure.</span>

<span class="sd">    solver: str, default=&quot;cd&quot;</span>
<span class="sd">        Solver to be used for the iterative estimation procedure.</span>
<span class="sd">        Alternatives are:</span>
<span class="sd">        &quot;cd&quot; - coordinate descent method.</span>
<span class="sd">        &quot;cvxpy&quot; - cvxpy solver.</span>

<span class="sd">    cd_max_iter: int, default=10000</span>
<span class="sd">        Maximum number of iterations to be perform by the coordinate</span>
<span class="sd">        descent algorithm before stopping.</span>

<span class="sd">    cd_tol: float, default=1e-10</span>
<span class="sd">        Convergence tolerance for the coordinate descent algorithm.</span>

<span class="sd">    cvxpy_opts: dict, default=None</span>
<span class="sd">        Additional options to be passed to the cvxpy solver. See cvxpy</span>
<span class="sd">        documentation for more details:</span>
<span class="sd">        https://www.cvxpy.org/tutorial/advanced/index.html#solve-method-options</span>

<span class="sd">    zero_tol: float, default=1e-4</span>
<span class="sd">        Tolerance for the rounding of estimated coefficients to zero.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    results_: dict[&quot;PDS&quot;, &quot;CHS&quot;]</span>
<span class="sd">        Dictionary containing the 2-stage-least-squares estimates.</span>
<span class="sd">        Values are `linearmodels.iv.IV2SLS` objects. See:</span>
<span class="sd">        https://bashtage.github.io/linearmodels/iv/iv/linearmodels.iv.model.IV2SLS.html</span>
<span class="sd">        https://bashtage.github.io/linearmodels/iv/examples/basic-examples.html</span>

<span class="sd">    X_selected_: dict[list[str]]</span>
<span class="sd">        List of selected controls for each stage in the estimation.</span>

<span class="sd">    valid_vars_: list[str]</span>
<span class="sd">        List of variables for which standard errors and test</span>
<span class="sd">        statistics are valid.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] Chernozhukov, V., Hansen, C., &amp; Spindler, M. (2015).</span>
<span class="sd">        Post-selection and post-regularization inference in linear models with many</span>
<span class="sd">        controls and instruments. American Economic Review, 105(5), 486-90.</span>

<span class="sd">    .. [2] Belloni, A., Chernozhukov, V., &amp; Hansen, C. (2014).</span>
<span class="sd">        Inference on treatment effects after selection among high-dimensional controls.</span>
<span class="sd">        The Review of Economic Studies, 81(2), 608-650.</span>

<span class="sd">    .. [3] Ahrens, A., Hansen, C. B., &amp; Schaffer, M. (2019).</span>
<span class="sd">        PDSLASSO: Stata module for post-selection and</span>
<span class="sd">        post-regularization OLS or IV estimation and inference.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    ``LassoPDS`` is used in the setting</span>

<span class="sd">    .. math:: y_{i}=\\alpha d_{i}+x_{i}^{\prime} \\beta+\\varepsilon_{i}</span>

<span class="sd">    Where :math:`d_{i}` is a scalar exogenous variable (can also be low-dimensional vector)</span>
<span class="sd">    for which we are interested in a obtaining a consistent estimate with valid</span>
<span class="sd">    standard errors and test statistics in the presence of high-dimensional :math:`x_i`.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from rlassomodels import RlassoPDS</span>
<span class="sd">    &gt;&gt;&gt; X = np.random.randn(100, 20)</span>
<span class="sd">    &gt;&gt;&gt; d_exog = np.random.randn(100)</span>
<span class="sd">    &gt;&gt;&gt; y = np.random.randn(100)</span>
<span class="sd">    &gt;&gt;&gt; # Fit the model, use rlasso to select both controls and instruments</span>
<span class="sd">    &gt;&gt;&gt; rlasso_pds = RlassoPDS()</span>
<span class="sd">    &gt;&gt;&gt; rlasso_pds.fit(X, y, d_exog)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">post</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">sqrt</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">fit_intercept</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">cov_type</span><span class="o">=</span><span class="s2">&quot;nonrobust&quot;</span><span class="p">,</span>
        <span class="n">x_dependent</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">lasso_psi</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">prestd</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">n_corr</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
        <span class="n">max_iter</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="n">conv_tol</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span>
        <span class="n">n_sim</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span>
        <span class="n">c</span><span class="o">=</span><span class="mf">1.1</span><span class="p">,</span>
        <span class="n">gamma</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">solver</span><span class="o">=</span><span class="s2">&quot;cd&quot;</span><span class="p">,</span>
        <span class="n">cd_max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
        <span class="n">cd_tol</span><span class="o">=</span><span class="mf">1e-10</span><span class="p">,</span>
        <span class="n">cvxpy_opts</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">zero_tol</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span>
    <span class="p">):</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">select_X</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">select_Z</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">post</span><span class="o">=</span><span class="n">post</span><span class="p">,</span>
            <span class="n">sqrt</span><span class="o">=</span><span class="n">sqrt</span><span class="p">,</span>
            <span class="n">fit_intercept</span><span class="o">=</span><span class="n">fit_intercept</span><span class="p">,</span>
            <span class="n">cov_type</span><span class="o">=</span><span class="n">cov_type</span><span class="p">,</span>
            <span class="n">x_dependent</span><span class="o">=</span><span class="n">x_dependent</span><span class="p">,</span>
            <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span>
            <span class="n">lasso_psi</span><span class="o">=</span><span class="n">lasso_psi</span><span class="p">,</span>
            <span class="n">prestd</span><span class="o">=</span><span class="n">prestd</span><span class="p">,</span>
            <span class="n">n_corr</span><span class="o">=</span><span class="n">n_corr</span><span class="p">,</span>
            <span class="n">max_iter</span><span class="o">=</span><span class="n">max_iter</span><span class="p">,</span>
            <span class="n">conv_tol</span><span class="o">=</span><span class="n">conv_tol</span><span class="p">,</span>
            <span class="n">n_sim</span><span class="o">=</span><span class="n">n_sim</span><span class="p">,</span>
            <span class="n">c</span><span class="o">=</span><span class="n">c</span><span class="p">,</span>
            <span class="n">gamma</span><span class="o">=</span><span class="n">gamma</span><span class="p">,</span>
            <span class="n">solver</span><span class="o">=</span><span class="n">solver</span><span class="p">,</span>
            <span class="n">cd_max_iter</span><span class="o">=</span><span class="n">cd_max_iter</span><span class="p">,</span>
            <span class="n">cd_tol</span><span class="o">=</span><span class="n">cd_tol</span><span class="p">,</span>
            <span class="n">cvxpy_opts</span><span class="o">=</span><span class="n">cvxpy_opts</span><span class="p">,</span>
            <span class="n">zero_tol</span><span class="o">=</span><span class="n">zero_tol</span><span class="p">,</span>
        <span class="p">)</span>

<div class="viewcode-block" id="RlassoPDS.fit"><a class="viewcode-back" href="../../generated/rlassomodels.RlassoPDS.html#rlassomodels.RlassoPDS.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">D_exog</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Fit the model.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X: array-like, shape (n_samples, n_controls)</span>
<span class="sd">            High-dimensional control variables.</span>

<span class="sd">        y: array-like, shape (n_samples,)</span>
<span class="sd">            Outcome/dependent variable.</span>

<span class="sd">        D_exog: array-like, shape (n_samples, n_exog)</span>
<span class="sd">            Low-dimensionnal exogenous regressors. On which inference</span>
<span class="sd">            is performed.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self : object</span>
<span class="sd">            Returns the instance itself.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">D_exog</span><span class="p">)</span></div></div>
</pre></div>

          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../index.html">RlassoModels</a></h1>








<h3>Navigation</h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../install.html">Install</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../examples.html">Examples</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../api_reference.html">API Documentation</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../index.html">Documentation overview</a><ul>
  <li><a href="../index.html">Module code</a><ul>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2022, Matias Piqueras.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 4.5.0</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
    </div>

    

    
  </body>
</html>